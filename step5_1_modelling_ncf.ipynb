{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Collaborative Filtering With Time Decay\n",
    "Our team has developed a recommendation model using Neural Collaborative Filtering (NCF), combining Matrix Factorisation with a Neural Network to perform collaborative filtering. This hybrid approach enables the model to capture both linear and non-linear relationships, enhancing its ability to predict user preferences effectively. We’ve further incorporated a Time Decay factor into the predicted watch ratio, which prioritises newer content by giving it a higher predicted watch ratio. This enables our recommendation system to prioritise trending or recent videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your root directory below. Make sure the `/data` and `/data_exports` folders are uploaded and is situated in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust your root directory\n",
    "root = '/content/drive/MyDrive/KuaiRec/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Train and Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training data: 2552082\n",
      "Total number of validation data: 1376299\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "train = pd.read_csv(root + \"data_exports/joined_train_data_segmented.csv\")\n",
    "val = pd.read_csv(root + \"data_exports/joined_val_data_FE.csv\")\n",
    "\n",
    "print(f'Total number of training data: {len(train)}')\n",
    "print(f'Total number of validation data: {len(val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>time</th>\n",
       "      <th>watch_ratio</th>\n",
       "      <th>user_active_degree</th>\n",
       "      <th>is_lowactive_period</th>\n",
       "      <th>is_live_streamer</th>\n",
       "      <th>is_video_author</th>\n",
       "      <th>follow_user_num</th>\n",
       "      <th>fans_user_num</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_daily_watch_time</th>\n",
       "      <th>top_3_categories</th>\n",
       "      <th>cluster</th>\n",
       "      <th>News_Politics</th>\n",
       "      <th>Auto_Tech</th>\n",
       "      <th>Lifestyle</th>\n",
       "      <th>Sports_Fitness</th>\n",
       "      <th>Entertainment</th>\n",
       "      <th>Culture</th>\n",
       "      <th>Others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>148</td>\n",
       "      <td>2020-07-05 05:27:48.378</td>\n",
       "      <td>0.722103</td>\n",
       "      <td>full_active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8.360719e+12</td>\n",
       "      <td>['Car', 'Pets', 'Real estate家居']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>183</td>\n",
       "      <td>2020-07-05 05:28:00.057</td>\n",
       "      <td>1.907377</td>\n",
       "      <td>full_active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8.360719e+12</td>\n",
       "      <td>['Car', 'Pets', 'Real estate家居']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>3649</td>\n",
       "      <td>2020-07-05 05:29:09.479</td>\n",
       "      <td>2.063311</td>\n",
       "      <td>full_active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8.360719e+12</td>\n",
       "      <td>['Car', 'Pets', 'Real estate家居']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>5262</td>\n",
       "      <td>2020-07-05 05:30:43.285</td>\n",
       "      <td>0.566388</td>\n",
       "      <td>full_active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8.360719e+12</td>\n",
       "      <td>['Car', 'Pets', 'Real estate家居']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>8234</td>\n",
       "      <td>2020-07-05 05:35:43.459</td>\n",
       "      <td>0.418364</td>\n",
       "      <td>full_active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8.360719e+12</td>\n",
       "      <td>['Car', 'Pets', 'Real estate家居']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  video_id                     time  watch_ratio user_active_degree  \\\n",
       "0       14       148  2020-07-05 05:27:48.378     0.722103        full_active   \n",
       "1       14       183  2020-07-05 05:28:00.057     1.907377        full_active   \n",
       "2       14      3649  2020-07-05 05:29:09.479     2.063311        full_active   \n",
       "3       14      5262  2020-07-05 05:30:43.285     0.566388        full_active   \n",
       "4       14      8234  2020-07-05 05:35:43.459     0.418364        full_active   \n",
       "\n",
       "   is_lowactive_period  is_live_streamer  is_video_author  follow_user_num  \\\n",
       "0                    0                 0                1               73   \n",
       "1                    0                 0                1               73   \n",
       "2                    0                 0                1               73   \n",
       "3                    0                 0                1               73   \n",
       "4                    0                 0                1               73   \n",
       "\n",
       "   fans_user_num  ...  avg_daily_watch_time                  top_3_categories  \\\n",
       "0              6  ...          8.360719e+12  ['Car', 'Pets', 'Real estate家居']   \n",
       "1              6  ...          8.360719e+12  ['Car', 'Pets', 'Real estate家居']   \n",
       "2              6  ...          8.360719e+12  ['Car', 'Pets', 'Real estate家居']   \n",
       "3              6  ...          8.360719e+12  ['Car', 'Pets', 'Real estate家居']   \n",
       "4              6  ...          8.360719e+12  ['Car', 'Pets', 'Real estate家居']   \n",
       "\n",
       "   cluster News_Politics Auto_Tech  Lifestyle  Sports_Fitness  Entertainment  \\\n",
       "0        0             0         1          1               0              0   \n",
       "1        0             0         1          1               0              0   \n",
       "2        0             0         1          1               0              0   \n",
       "3        0             0         1          1               0              0   \n",
       "4        0             0         1          1               0              0   \n",
       "\n",
       "   Culture  Others  \n",
       "0        0       1  \n",
       "1        0       1  \n",
       "2        0       1  \n",
       "3        0       1  \n",
       "4        0       1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving Video Age\n",
    "\n",
    "To calculate the age of each video in days, we first require a reference date, which serves as a baseline for computing the time decay in our model. For consistency, we assume this date to be the day of the latest recorded interaction within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date: 2020-08-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Convert type to datetime\n",
    "train['time'] = pd.to_datetime(train['time'])\n",
    "\n",
    "# Assume current date is the next day of the last date\n",
    "CURRENT_DATE_TRAIN = pd.to_datetime(train['time'].dt.date.max())\n",
    "\n",
    "# Just the date portion\n",
    "print(f'Current date: {CURRENT_DATE_TRAIN}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are then able to calculate the age of each video in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info = pd.read_csv(root + 'data/item_daily_features.csv', usecols=['video_id', 'upload_dt']).drop_duplicates()\n",
    "\n",
    "video_info['upload_dt'] = pd.to_datetime(video_info['upload_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get video age for training data\n",
    "video_info_train = video_info[video_info['video_id'].isin(train['video_id'].unique())]\n",
    "video_info_train['video_age'] = (CURRENT_DATE_TRAIN - video_info_train['upload_dt']).dt.days\n",
    "video_age_dict = video_info_train.set_index('video_id')['video_age'].to_dict()    # Convert to dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Feeding into the Neural Network Component of NCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encode categorical variables\n",
    "\n",
    "Since neural networks require numerical inputs, we need to transform categorical variables, like `user_active_degree` and `time_period`, into a numerical format. We achieve this by one-hot encoding, which converts each category into a distinct binary vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode 'user_active_degree', 'time_period'\n",
    "train_processed = pd.get_dummies(train, columns=['user_active_degree', 'time_period'])\n",
    "\n",
    "# Remove the column for user_active_degree = UNKNOWN\n",
    "train_processed = train_processed.drop(columns=['user_active_degree_UNKNOWN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale continuous variables\n",
    "\n",
    "Our continuous features currently have varying scales: for instance, as seen below, `follow_user_num` is typically in the tens, whereas `like_cnt` can range from tens to hundreds of thousands. Without scaling, these differences would lead to imbalances during training, causing certain features to disproportionately influence the model. To address this, we apply feature scaling to standardise the values, ensuring each feature contributes more equally to model learning and improving overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>follow_user_num</th>\n",
       "      <th>fans_user_num</th>\n",
       "      <th>friend_user_num</th>\n",
       "      <th>register_days</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>show_cnt</th>\n",
       "      <th>play_cnt</th>\n",
       "      <th>like_cnt</th>\n",
       "      <th>comment_cnt</th>\n",
       "      <th>share_cnt</th>\n",
       "      <th>follow_cnt</th>\n",
       "      <th>collect_cnt</th>\n",
       "      <th>count_afternoon_views</th>\n",
       "      <th>count_evening_views</th>\n",
       "      <th>count_midnight_views</th>\n",
       "      <th>count_morning_views</th>\n",
       "      <th>avg_daily_watch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.00</td>\n",
       "      <td>2.552082e+06</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2.552082e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.814</td>\n",
       "      <td>3.873</td>\n",
       "      <td>1.332</td>\n",
       "      <td>265.334</td>\n",
       "      <td>11647.906</td>\n",
       "      <td>6959049.23</td>\n",
       "      <td>7.052437e+06</td>\n",
       "      <td>204477.960</td>\n",
       "      <td>8935.899</td>\n",
       "      <td>3805.251</td>\n",
       "      <td>20932.721</td>\n",
       "      <td>285.876</td>\n",
       "      <td>465.834</td>\n",
       "      <td>280.911</td>\n",
       "      <td>457.937</td>\n",
       "      <td>610.060</td>\n",
       "      <td>8.062631e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>141.890</td>\n",
       "      <td>9.717</td>\n",
       "      <td>4.925</td>\n",
       "      <td>264.071</td>\n",
       "      <td>13441.156</td>\n",
       "      <td>9275604.90</td>\n",
       "      <td>9.511481e+06</td>\n",
       "      <td>320943.089</td>\n",
       "      <td>21119.828</td>\n",
       "      <td>12695.305</td>\n",
       "      <td>63310.055</td>\n",
       "      <td>1337.505</td>\n",
       "      <td>284.492</td>\n",
       "      <td>238.512</td>\n",
       "      <td>433.983</td>\n",
       "      <td>330.571</td>\n",
       "      <td>7.068827e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3066.000</td>\n",
       "      <td>644.00</td>\n",
       "      <td>3.310000e+02</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.632392e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>119.000</td>\n",
       "      <td>7333.000</td>\n",
       "      <td>832913.00</td>\n",
       "      <td>7.629220e+05</td>\n",
       "      <td>15528.000</td>\n",
       "      <td>345.000</td>\n",
       "      <td>64.000</td>\n",
       "      <td>1002.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>249.000</td>\n",
       "      <td>84.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>374.000</td>\n",
       "      <td>7.686325e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>9383.000</td>\n",
       "      <td>3127692.00</td>\n",
       "      <td>3.071419e+06</td>\n",
       "      <td>73590.000</td>\n",
       "      <td>2171.000</td>\n",
       "      <td>414.000</td>\n",
       "      <td>4968.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>444.000</td>\n",
       "      <td>225.000</td>\n",
       "      <td>356.000</td>\n",
       "      <td>569.000</td>\n",
       "      <td>8.158000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>43.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>302.000</td>\n",
       "      <td>11500.000</td>\n",
       "      <td>9372330.00</td>\n",
       "      <td>9.544620e+06</td>\n",
       "      <td>251209.000</td>\n",
       "      <td>8918.000</td>\n",
       "      <td>2275.000</td>\n",
       "      <td>17978.000</td>\n",
       "      <td>133.000</td>\n",
       "      <td>656.000</td>\n",
       "      <td>419.000</td>\n",
       "      <td>748.000</td>\n",
       "      <td>806.000</td>\n",
       "      <td>8.518700e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1811.000</td>\n",
       "      <td>251.000</td>\n",
       "      <td>71.000</td>\n",
       "      <td>2002.000</td>\n",
       "      <td>294520.000</td>\n",
       "      <td>65255077.00</td>\n",
       "      <td>6.479578e+07</td>\n",
       "      <td>2762854.000</td>\n",
       "      <td>338365.000</td>\n",
       "      <td>206105.000</td>\n",
       "      <td>1215372.000</td>\n",
       "      <td>29197.000</td>\n",
       "      <td>1477.000</td>\n",
       "      <td>1435.000</td>\n",
       "      <td>1852.000</td>\n",
       "      <td>1727.000</td>\n",
       "      <td>1.277244e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       follow_user_num  fans_user_num  friend_user_num  register_days  \\\n",
       "count      2552082.000    2552082.000      2552082.000    2552082.000   \n",
       "mean            53.814          3.873            1.332        265.334   \n",
       "std            141.890          9.717            4.925        264.071   \n",
       "min              0.000          0.000            0.000          8.000   \n",
       "25%              7.000          0.000            0.000        119.000   \n",
       "50%             15.000          1.000            0.000        200.000   \n",
       "75%             43.000          4.000            1.000        302.000   \n",
       "max           1811.000        251.000           71.000       2002.000   \n",
       "\n",
       "       video_duration     show_cnt      play_cnt     like_cnt  comment_cnt  \\\n",
       "count     2552082.000   2552082.00  2.552082e+06  2552082.000  2552082.000   \n",
       "mean        11647.906   6959049.23  7.052437e+06   204477.960     8935.899   \n",
       "std         13441.156   9275604.90  9.511481e+06   320943.089    21119.828   \n",
       "min          3066.000       644.00  3.310000e+02        2.000        0.000   \n",
       "25%          7333.000    832913.00  7.629220e+05    15528.000      345.000   \n",
       "50%          9383.000   3127692.00  3.071419e+06    73590.000     2171.000   \n",
       "75%         11500.000   9372330.00  9.544620e+06   251209.000     8918.000   \n",
       "max        294520.000  65255077.00  6.479578e+07  2762854.000   338365.000   \n",
       "\n",
       "         share_cnt   follow_cnt  collect_cnt  count_afternoon_views  \\\n",
       "count  2552082.000  2552082.000  2552082.000            2552082.000   \n",
       "mean      3805.251    20932.721      285.876                465.834   \n",
       "std      12695.305    63310.055     1337.505                284.492   \n",
       "min          0.000        0.000        0.000                  0.000   \n",
       "25%         64.000     1002.000        5.000                249.000   \n",
       "50%        414.000     4968.000       28.000                444.000   \n",
       "75%       2275.000    17978.000      133.000                656.000   \n",
       "max     206105.000  1215372.000    29197.000               1477.000   \n",
       "\n",
       "       count_evening_views  count_midnight_views  count_morning_views  \\\n",
       "count          2552082.000           2552082.000          2552082.000   \n",
       "mean               280.911               457.937              610.060   \n",
       "std                238.512               433.983              330.571   \n",
       "min                  0.000                 0.000                0.000   \n",
       "25%                 84.000                53.000              374.000   \n",
       "50%                225.000               356.000              569.000   \n",
       "75%                419.000               748.000              806.000   \n",
       "max               1435.000              1852.000             1727.000   \n",
       "\n",
       "       avg_daily_watch_time  \n",
       "count          2.552082e+06  \n",
       "mean           8.062631e+12  \n",
       "std            7.068827e+11  \n",
       "min            4.632392e+12  \n",
       "25%            7.686325e+12  \n",
       "50%            8.158000e+12  \n",
       "75%            8.518700e+12  \n",
       "max            1.277244e+13  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed[['follow_user_num',\n",
    "       'fans_user_num', 'friend_user_num', 'register_days', 'video_duration',\n",
    "       'show_cnt', 'play_cnt', 'like_cnt', 'comment_cnt',\n",
    "       'share_cnt', 'follow_cnt', 'collect_cnt', 'count_afternoon_views', 'count_evening_views', 'count_midnight_views',\n",
    "       'count_morning_views', 'avg_daily_watch_time']].describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "columns_to_scale = ['follow_user_num',\n",
    "       'fans_user_num', 'friend_user_num', 'register_days', 'video_duration',\n",
    "       'show_cnt', 'play_cnt', \n",
    "       'like_cnt', 'comment_cnt',\n",
    "       'share_cnt', 'follow_cnt', 'collect_cnt', \n",
    "       'total_connections',\n",
    "       'watch_frequency', \n",
    "       'count_afternoon_views', 'count_evening_views', 'count_midnight_views',\n",
    "       'count_morning_views', \n",
    "       'avg_daily_watch_time', \n",
    "       ]\n",
    "\n",
    "train_processed[columns_to_scale] = scaler.fit_transform(train_processed[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see that the mean of all features is (close to) 0 with standard deviation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>follow_user_num</th>\n",
       "      <th>fans_user_num</th>\n",
       "      <th>friend_user_num</th>\n",
       "      <th>register_days</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>show_cnt</th>\n",
       "      <th>play_cnt</th>\n",
       "      <th>like_cnt</th>\n",
       "      <th>comment_cnt</th>\n",
       "      <th>share_cnt</th>\n",
       "      <th>follow_cnt</th>\n",
       "      <th>collect_cnt</th>\n",
       "      <th>count_afternoon_views</th>\n",
       "      <th>count_evening_views</th>\n",
       "      <th>count_midnight_views</th>\n",
       "      <th>count_morning_views</th>\n",
       "      <th>avg_daily_watch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "      <td>2552082.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.379</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>-0.638</td>\n",
       "      <td>-0.750</td>\n",
       "      <td>-0.741</td>\n",
       "      <td>-0.637</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-1.637</td>\n",
       "      <td>-1.178</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>-1.845</td>\n",
       "      <td>-4.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.330</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.554</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.660</td>\n",
       "      <td>-0.661</td>\n",
       "      <td>-0.589</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-0.762</td>\n",
       "      <td>-0.826</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>-0.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.274</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.413</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.146</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.384</td>\n",
       "      <td>25.433</td>\n",
       "      <td>14.146</td>\n",
       "      <td>6.577</td>\n",
       "      <td>21.045</td>\n",
       "      <td>6.285</td>\n",
       "      <td>6.071</td>\n",
       "      <td>7.971</td>\n",
       "      <td>15.598</td>\n",
       "      <td>15.935</td>\n",
       "      <td>18.867</td>\n",
       "      <td>21.616</td>\n",
       "      <td>3.554</td>\n",
       "      <td>4.839</td>\n",
       "      <td>3.212</td>\n",
       "      <td>3.379</td>\n",
       "      <td>6.663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       follow_user_num  fans_user_num  friend_user_num  register_days  \\\n",
       "count      2552082.000    2552082.000      2552082.000    2552082.000   \n",
       "mean             0.000         -0.000            0.000         -0.000   \n",
       "std              1.000          1.000            1.000          1.000   \n",
       "min             -0.379         -0.399           -0.270         -0.974   \n",
       "25%             -0.330         -0.399           -0.270         -0.554   \n",
       "50%             -0.274         -0.296           -0.270         -0.247   \n",
       "75%             -0.076          0.013           -0.067          0.139   \n",
       "max             12.384         25.433           14.146          6.577   \n",
       "\n",
       "       video_duration     show_cnt     play_cnt     like_cnt  comment_cnt  \\\n",
       "count     2552082.000  2552082.000  2552082.000  2552082.000  2552082.000   \n",
       "mean           -0.000        0.000        0.000       -0.000       -0.000   \n",
       "std             1.000        1.000        1.000        1.000        1.000   \n",
       "min            -0.638       -0.750       -0.741       -0.637       -0.423   \n",
       "25%            -0.321       -0.660       -0.661       -0.589       -0.407   \n",
       "50%            -0.169       -0.413       -0.419       -0.408       -0.320   \n",
       "75%            -0.011        0.260        0.262        0.146       -0.001   \n",
       "max            21.045        6.285        6.071        7.971       15.598   \n",
       "\n",
       "         share_cnt   follow_cnt  collect_cnt  count_afternoon_views  \\\n",
       "count  2552082.000  2552082.000  2552082.000            2552082.000   \n",
       "mean        -0.000       -0.000        0.000                 -0.000   \n",
       "std          1.000        1.000        1.000                  1.000   \n",
       "min         -0.300       -0.331       -0.214                 -1.637   \n",
       "25%         -0.295       -0.315       -0.210                 -0.762   \n",
       "50%         -0.267       -0.252       -0.193                 -0.077   \n",
       "75%         -0.121       -0.047       -0.114                  0.668   \n",
       "max         15.935       18.867       21.616                  3.554   \n",
       "\n",
       "       count_evening_views  count_midnight_views  count_morning_views  \\\n",
       "count          2552082.000           2552082.000          2552082.000   \n",
       "mean                -0.000                 0.000                0.000   \n",
       "std                  1.000                 1.000                1.000   \n",
       "min                 -1.178                -1.055               -1.845   \n",
       "25%                 -0.826                -0.933               -0.714   \n",
       "50%                 -0.234                -0.235               -0.124   \n",
       "75%                  0.579                 0.668                0.593   \n",
       "max                  4.839                 3.212                3.379   \n",
       "\n",
       "       avg_daily_watch_time  \n",
       "count           2552082.000  \n",
       "mean                 -0.000  \n",
       "std                   1.000  \n",
       "min                  -4.853  \n",
       "25%                  -0.532  \n",
       "50%                   0.135  \n",
       "75%                   0.645  \n",
       "max                   6.663  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round to 3 dp\n",
    "train_processed[['follow_user_num',\n",
    "       'fans_user_num', 'friend_user_num', 'register_days', 'video_duration',\n",
    "       'show_cnt', 'play_cnt', 'like_cnt', 'comment_cnt',\n",
    "       'share_cnt', 'follow_cnt', 'collect_cnt', 'count_afternoon_views', 'count_evening_views', 'count_midnight_views',\n",
    "       'count_morning_views', 'avg_daily_watch_time']].describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dataset Class\n",
    "\n",
    "To encapsulate the dataset effectively, we implement a KuaiShouDataset class. This class holds essential components, including encoders for user and video IDs, user and video features, the target variable (`watch_ratio`), and a dictionary for video_age. By centralising these elements, the KuaiShouDataset class streamlines data access and processing, allowing efficient and more convinient handling of features and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KuaiShouDataset(Dataset):\n",
    "    def __init__(self, data, user_id_col, video_id_col, user_feature_cols, video_feature_cols, watch_ratio_col, video_age_dict):\n",
    "        self.user_feature_cols = user_feature_cols\n",
    "        self.video_feature_cols = video_feature_cols\n",
    "\n",
    "        # Initialise and fit LabelEncoders\n",
    "        self.user_encoder = LabelEncoder()\n",
    "        self.video_encoder = LabelEncoder()\n",
    "        \n",
    "        self.user_indices = torch.tensor(self.user_encoder.fit_transform(data[user_id_col]), dtype=torch.long)\n",
    "        self.video_indices = torch.tensor(self.video_encoder.fit_transform(data[video_id_col]), dtype=torch.long)\n",
    "\n",
    "        # Convert user and video features and watch ratios to tensors\n",
    "        self.user_features = torch.tensor(data[user_feature_cols].values.astype(np.float32), dtype=torch.float32)\n",
    "        self.video_features = torch.tensor(data[video_feature_cols].values.astype(np.float32), dtype=torch.float32)\n",
    "        self.watch_ratios = torch.tensor(data[watch_ratio_col].values.astype(np.float32), dtype=torch.float32)\n",
    "\n",
    "        # Time related features\n",
    "        self.video_age_dict = video_age_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_indices[idx], self.video_indices[idx], self.user_features[idx], self.video_features[idx], self.watch_ratios[idx]\n",
    "\n",
    "    def inverse_transform_user_ids(self, encoded_user_idx):\n",
    "        \"\"\"Decode encoded user indices to original user_ids.\"\"\"\n",
    "        return self.user_encoder.inverse_transform(encoded_user_idx)\n",
    "    \n",
    "    def inverse_transform_video_ids(self, encoded_video_idx):\n",
    "        \"\"\"Decode encoded video indices to original video_ids.\"\"\"\n",
    "        return self.video_encoder.inverse_transform(encoded_video_idx)\n",
    "    \n",
    "    def get_video_age(self, video_idx):\n",
    "        \"\"\"Get video age.\"\"\"\n",
    "        video_ids = self.inverse_transform_video_ids(video_idx)\n",
    "\n",
    "        ages = []\n",
    "        for i in range(len(video_idx)):\n",
    "            ages.append(self.video_age_dict[video_ids[i]])\n",
    "        return torch.tensor(ages, dtype=torch.float32)\n",
    "    \n",
    "    def get_decoded_user_video_pairs(self):\n",
    "        \"\"\"Get decoded user-video pairs.\"\"\"\n",
    "        return self.inverse_transform_user_ids(self.user_indices), self.inverse_transform_video_ids(self.video_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model Architecture\n",
    "\n",
    "We designed our Neural Collaborative Filtering (NCF) model with a multi-branch architecture, combining a Generalised Matrix Factorization (GMF) component with two Multi-Layer Perceptron (MLP) components. Each branch serves a distinct purpose: the GMF branch captures linear interactions between users and videos, while the MLP branches—one for embeddings and one for additional features—model complex, non-linear interactions.\n",
    "- **GMF Component**: This branch computes element-wise interactions between user and video embeddings to capture collaborative signals directly.\n",
    "- **MLP Components**: We use two MLP branches. One MLP processes separate user and video embeddings, while the other processes user and video features together. In each MLP layer, we apply Batch Normalisation and ReLU activation to stabilise and enhance learning, along with Dropout to mitigate overfitting.\n",
    "\n",
    "The outputs from the GMF and MLP components are concatenated, then passed through a fully connected layer to produce the final predicted watch ratio. By blending GMF and MLP outputs, our model can capture both linear and complex patterns.\n",
    "\n",
    "_(insert diagram here)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_videos, embedding_dim, num_user_features, num_video_features, dropout):\n",
    "        super(NCF, self).__init__()\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # GMF Components for embeddings\n",
    "        self.user_embeddings_gmf = nn.Embedding(num_users, embedding_dim)\n",
    "        self.video_embeddings_gmf = nn.Embedding(num_videos, embedding_dim)\n",
    "\n",
    "        # MLP Components for embeddings\n",
    "        self.user_embeddings_mlp = nn.Embedding(num_users, embedding_dim)\n",
    "        self.video_embeddings_mlp = nn.Embedding(num_videos, embedding_dim)\n",
    "\n",
    "        # MLP layers for user and video embeddings\n",
    "        self.fc1_mlp = nn.Linear(2 * embedding_dim, 128)\n",
    "        self.fc2_mlp = nn.Linear(128, 64)\n",
    "\n",
    "        # MLP layers for user and video features\n",
    "        self.user_video_features_fc1 = nn.Linear(num_user_features + num_video_features, 128)\n",
    "        self.user_video_features_fc2 = nn.Linear(128, 64)\n",
    "\n",
    "        # Final layers combining GMF, MLP for embeddings, and additional features\n",
    "        self.fc1_combined = nn.Linear(embedding_dim + 64 + 64, 128)\n",
    "        self.fc2_combined = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, user_idx, video_idx, user_features, video_features):\n",
    "        ####### GMF Embedding branch #######\n",
    "        user_emb_gmf = self.user_embeddings_gmf(user_idx)\n",
    "        video_emb_gmf = self.video_embeddings_gmf(video_idx)\n",
    "        gmf_output = user_emb_gmf * video_emb_gmf                                   # dimension: (batch_size, embedding_dim)\n",
    "\n",
    "        ####### MLP Embedding branch #######\n",
    "        user_emb_mlp = self.user_embeddings_mlp(user_idx)\n",
    "        video_emb_mlp = self.video_embeddings_mlp(video_idx)\n",
    "        mlp_input = torch.cat([user_emb_mlp, video_emb_mlp], dim=-1)                # dimension: (batch_size, 2 * embedding_dim)\n",
    "\n",
    "        # First fully connected layer with BatchNorm and ReLU\n",
    "        mlp_output = self.fc1_mlp(mlp_input)\n",
    "        if self.training:\n",
    "            mlp_output = nn.BatchNorm1d(128)(mlp_output)\n",
    "        mlp_output = torch.relu(mlp_output)\n",
    "        mlp_output = nn.Dropout(self.dropout)(mlp_output)\n",
    "\n",
    "        # Second fully connected layer with BatchNorm and ReLU\n",
    "        mlp_output = self.fc2_mlp(mlp_output)                                       # dimension: (batch_size, 64)\n",
    "        if self.training:\n",
    "            mlp_output = nn.BatchNorm1d(64)(mlp_output)\n",
    "        mlp_output = torch.relu(mlp_output)\n",
    "        mlp_output = nn.Dropout(self.dropout)(mlp_output)\n",
    "\n",
    "        ####### MLP Feature processing branch #######\n",
    "        user_video_features = torch.cat([user_features, video_features], dim=-1)\n",
    "\n",
    "        # First fully connected layer with BatchNorm and ReLU\n",
    "        user_video_features_processed = self.user_video_features_fc1(user_video_features)  # dimension: (batch_size, 128)\n",
    "        if self.training:\n",
    "            user_video_features_processed = nn.BatchNorm1d(128)(user_video_features_processed)\n",
    "        user_video_features_processed = torch.relu(user_video_features_processed)\n",
    "        user_video_features_processed = nn.Dropout(self.dropout)(user_video_features_processed)\n",
    "\n",
    "        # Second fully connected layer with BatchNorm and ReLU\n",
    "        user_video_features_processed = self.user_video_features_fc2(user_video_features_processed)  # dimension: (batch_size, 64)\n",
    "        if self.training:\n",
    "            user_video_features_processed = nn.BatchNorm1d(64)(user_video_features_processed)\n",
    "        user_video_features_processed = torch.relu(user_video_features_processed)\n",
    "        user_video_features_processed = nn.Dropout(self.dropout)(user_video_features_processed)\n",
    "\n",
    "        ####### Combine GMF, MLP, and additional features #######\n",
    "        combined_input = torch.cat([gmf_output, mlp_output, user_video_features_processed], dim=-1)\n",
    "        combined_output = self.fc1_combined(combined_input)\n",
    "        combined_output = torch.relu(combined_output)\n",
    "        combined_output = nn.Dropout(self.dropout)(combined_output)\n",
    "\n",
    "        combined_output = self.fc2_combined(combined_output)\n",
    "        combined_output = torch.sigmoid(combined_output) * 5\n",
    "        \n",
    "        return combined_output.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Recommendation System\n",
    "\n",
    "We encapsulate the recommendation system in a class, `KuaiShou_NCF_RecSys`, designed to handle the training and prediction phases efficiently. This class is built to accept training data and model specifications and enables scalable batch-based predictions for each user-video combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KuaiShou_NCF_RecSys:\n",
    "    def __init__(self, dataset_train: KuaiShouDataset, model: nn.Module, embedding_dim: int, dropout: float, decay: float):\n",
    "        self.dataset = dataset_train\n",
    "        self.num_users = len(dataset_train.user_encoder.classes_)\n",
    "        self.num_videos = len(dataset_train.video_encoder.classes_)\n",
    "        self.num_user_features = len(dataset_train.user_feature_cols)\n",
    "        self.num_video_features = len(dataset_train.video_feature_cols)\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Move model to GPU if available\n",
    "        \n",
    "        # Initialise the model\n",
    "        self.model: nn.Module = model(self.num_users, self.num_videos, embedding_dim, self.num_user_features, self.num_video_features, dropout)\n",
    "\n",
    "        # Time decay constants\n",
    "        self.decay = decay\n",
    "\n",
    "    def train(self, batch_size: int, num_epochs: int, lr: int, criterion, optimizer):\n",
    "        # Initialise the DataLoader\n",
    "        train_loader = DataLoader(self.dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        print(f\"Model moved to {self.device}\")\n",
    "\n",
    "        # Optimizer and loss function\n",
    "        optimizer = optimizer(self.model.parameters(), lr=lr)\n",
    "        criterion = criterion\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "            \n",
    "            for user_idx, video_idx, user_features, video_features, watch_ratio in train_loader:\n",
    "                user_idx, video_idx, user_features, video_features, watch_ratio = user_idx.to(self.device), video_idx.to(self.device), user_features.to(self.device), video_features.to(self.device), watch_ratio.to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(user_idx, video_idx, user_features, video_features)\n",
    "                loss = criterion(outputs, watch_ratio)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Accumulate loss for reporting\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            # Print loss for each epoch\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    def predict(self, batch_size=1024):\n",
    "        \"\"\"\n",
    "        Generates a dataframe with predicted watch ratios for each user-video pair in batches.\n",
    "        \"\"\"\n",
    "        self.model.eval()  # Set model to evaluation mode\n",
    "        predictions_df = pd.DataFrame(columns=['user_id', 'video_id', 'watch_ratio'])\n",
    "\n",
    "        for start_user_idx in range(0, self.num_users, batch_size):\n",
    "            end_user_idx = min(start_user_idx + batch_size, self.num_users)\n",
    "            user_indices = torch.arange(start_user_idx, end_user_idx, dtype=torch.long).to(self.device)\n",
    "\n",
    "            # Gather user features in batch\n",
    "            user_features_batch = self.dataset.user_features[user_indices].to(self.device)\n",
    "            \n",
    "            for video_idx in range(self.num_videos):\n",
    "                video_indices_tensor = torch.tensor([video_idx], dtype=torch.long).to(self.device)\n",
    "                video_feature_tensor = self.dataset.video_features[video_idx].unsqueeze(0).to(self.device)\n",
    "                video_age = self.dataset.get_video_age(video_indices_tensor).to(self.device)\n",
    "                \n",
    "                # Repeat video data for the entire user batch\n",
    "                video_tensor_batch = video_indices_tensor.expand(len(user_indices))\n",
    "                video_feature_batch = video_feature_tensor.expand(len(user_indices), -1)\n",
    "                video_age_batch = video_age.expand(len(user_indices))\n",
    "\n",
    "                # Predict in batch\n",
    "                with torch.no_grad():\n",
    "                    predicted_watch_ratios = self.model(user_indices, video_tensor_batch, user_features_batch, video_feature_batch)\n",
    "\n",
    "                # Apply time decay\n",
    "                decay_weights = self.calculate_exponential_weight(video_age_batch)\n",
    "                predicted_watch_ratios = predicted_watch_ratios * decay_weights\n",
    "                \n",
    "                # Append predictions to DataFrame\n",
    "                batch_predictions_df = pd.DataFrame({'user_id': self.dataset.inverse_transform_user_ids(user_indices),\n",
    "                                                    'video_id': self.dataset.inverse_transform_video_ids(video_tensor_batch),\n",
    "                                                    'watch_ratio': predicted_watch_ratios.cpu().numpy()})\n",
    "                predictions_df = pd.concat([predictions_df, batch_predictions_df])\n",
    "            \n",
    "        return predictions_df\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        \"\"\"\n",
    "        Returns the model parameters.\n",
    "        \"\"\"\n",
    "        return self.model.state_dict()\n",
    "    \n",
    "    def calculate_exponential_weight(self, video_age_days):\n",
    "        \"\"\"\n",
    "        Returns the decay weight based on the defined decay constant and the number of days since the video has been uploaded.\n",
    "        \"\"\"\n",
    "        return torch.exp(-self.decay * video_age_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Training Data to the Model and Generating Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the user and features which will be used in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns for user and video features in the user-item interaction data\n",
    "user_cols = ['is_lowactive_period',\n",
    "             'is_live_streamer', 'is_video_author', 'follow_user_num',\n",
    "             'fans_user_num', 'friend_user_num', 'register_days', 'is_new_user',\n",
    "             'total_connections', 'is_content_creator',\n",
    "             'watch_frequency', 'is_weekend_interaction', 'is_weekend',\n",
    "             'count_afternoon_views', 'count_evening_views', 'count_midnight_views', 'count_morning_views', \n",
    "             'avg_daily_watch_time', \n",
    "             'user_active_degree_full_active', 'user_active_degree_high_active', 'user_active_degree_middle_active', \n",
    "             'time_period_afternoon', 'time_period_evening', 'time_period_midnight', 'time_period_morning'\n",
    "            ]\n",
    "video_cols = ['video_duration', 'show_cnt', 'play_cnt', \n",
    "              'like_cnt', 'comment_cnt', 'share_cnt', 'follow_cnt', 'collect_cnt', \n",
    "              'News_Politics', 'Auto_Tech', 'Lifestyle', 'Sports_Fitness', 'Entertainment', 'Culture', 'Others',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function which allows us to train and predict using the NCF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(hyperparameters: dict, train_data: pd.DataFrame, video_age_train_dict, **kwargs):\n",
    "    cluster = kwargs.get('cluster', None)\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    BATCH_SIZE = hyperparameters['batch_size']\n",
    "    NUM_EPOCHS = hyperparameters['num_epochs']\n",
    "    LEARNING_RATE = hyperparameters['lr']\n",
    "    EMBEDDING_DIM = hyperparameters['embedding_dim']\n",
    "    DROPOUT = hyperparameters['dropout']\n",
    "    DECAY = hyperparameters['decay']\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimiser = optim.Adam\n",
    "\n",
    "    print(f\"----- Training {'' if cluster == None else f'for cluster {cluster} '}-----\")\n",
    "\n",
    "    # Create the dataset\n",
    "    dataset_train = KuaiShouDataset(train_data, 'user_id', 'video_id', user_cols, video_cols, 'watch_ratio', video_age_train_dict)\n",
    "\n",
    "    # Initialise the NCF model\n",
    "    print(\"Initialising...\")\n",
    "    ncf_rec_sys = KuaiShou_NCF_RecSys(dataset_train, NCF, EMBEDDING_DIM, DROPOUT, DECAY)\n",
    "\n",
    "    # Train on data\n",
    "    ncf_rec_sys.train(BATCH_SIZE, NUM_EPOCHS, LEARNING_RATE, criterion, optimiser)\n",
    "\n",
    "    # Generate predictions\n",
    "    print(\"Generating predictions...\")\n",
    "    predictions_df = ncf_rec_sys.predict()\n",
    "    \n",
    "    print(\"Complete!\")\n",
    "    return cluster, predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our customer segmentation process, we divided users into four distinct clusters based on their behavioral patterns. Each cluster exhibits unique characteristics, enabling us to tailor training specifically to each segment.\n",
    "\n",
    "By training our model within each cluster, we enhance its ability to capture subtle patterns unique to each group. This approach not only improves model performance by focusing on relevant behaviors but also reduces computational complexity by minimising the dataset size for each cluster. This method allows for more efficient training and provides more personalised recommendations for each user segment.\n",
    "\n",
    "After training with segmentation, we will also train the model on the full dataset, without segmentation, to compare and evaluate the impact of clustering on recommendation performance.\n",
    "\n",
    "In addition, we will be performing a grid search across several hyperparameters to identify the best-performing hyperparameters. In doing so, we have held out another 20% of the latest user-video interactions from the training data for 'internal validation' and selection of the best hyperparameters, based on the average watch_ratio @ 100. This prevents data leakage and tuning on the validation/test sets.\n",
    "\n",
    "However, do note that the notebook is ran across several days, across several PCs, and it may take a long time to re-run these parameters. Therefore, we recommend skipping running the section, and go straight into the final training of the model on the entire train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_by_cluster_and_without(params: dict, data: pd.DataFrame, video_age_dict: dict,\n",
    "                                train_by_cluster: bool = True, train_without_clustering: bool = False, \n",
    "                                is_final: bool = False):\n",
    "    param_str = '_'.join([f'{key}{val}' for key, val in params.items()])\n",
    "    \n",
    "    # Split data based on time (last 20% for validation)\n",
    "    time_threshold = np.percentile(data['time'], 80)\n",
    "    train_data = data[data['time'] <= time_threshold]\n",
    "    val_data = data[data['time'] > time_threshold]\n",
    "\n",
    "    # Create directory to save predictions\n",
    "    if not os.path.exists(root + 'recommendations'):\n",
    "            os.makedirs(root + 'recommendations')\n",
    "    \n",
    "    # Train for each cluster\n",
    "    if train_by_cluster:\n",
    "        cluster_predictions = {}\n",
    "        cluster_val_metrics = []\n",
    "        \n",
    "        for cluster in sorted(train_data['cluster'].unique()):\n",
    "            train_cluster = train_data[train_data['cluster'] == cluster]\n",
    "            val_cluster = val_data[val_data['cluster'] == cluster]\n",
    "            \n",
    "            # Train and get predictions\n",
    "            cluster, predictions_df = train_and_predict(params, train_cluster, video_age_dict, \n",
    "                                                      validation_data=val_cluster, **{'cluster': cluster})\n",
    "            \n",
    "            # Store predictions\n",
    "            cluster_predictions[cluster] = predictions_df\n",
    "            \n",
    "            # Calculate validation metrics for this cluster\n",
    "            if len(val_cluster) > 0:\n",
    "                val_predictions = predictions_df[\n",
    "                    predictions_df['user_id'].isin(val_cluster['user_id']) & \n",
    "                    predictions_df['video_id'].isin(val_cluster['video_id'])\n",
    "                ]\n",
    "                \n",
    "                # Calculate watch_ratio@100 for validation set\n",
    "                top_100_preds = val_predictions.nlargest(100, 'watch_ratio')['video_id']\n",
    "                avg_watch_ratio = val_data[val_data['video_id'].isin(top_100_preds)]['watch_ratio'].mean()\n",
    "                \n",
    "                cluster_val_metrics.append({\n",
    "                    'cluster': cluster,\n",
    "                    'watch_ratio@100': avg_watch_ratio,\n",
    "                    'val_size': len(val_cluster)\n",
    "                })\n",
    "        \n",
    "        # Combine predictions\n",
    "        watch_ratio_predictions_df = pd.DataFrame()\n",
    "        for cluster, df in cluster_predictions.items():\n",
    "            cluster_predictions_df = df\n",
    "            cluster_predictions_df['cluster'] = cluster\n",
    "            watch_ratio_predictions_df = pd.concat([watch_ratio_predictions_df, cluster_predictions_df])\n",
    "        \n",
    "        # Calculate overall weighted validation metric\n",
    "        if cluster_val_metrics:\n",
    "            metrics_df = pd.DataFrame(cluster_val_metrics)\n",
    "            weighted_watch_ratio = np.average(\n",
    "                metrics_df['watch_ratio@100'],\n",
    "                weights=metrics_df['val_size']\n",
    "            )\n",
    "            print(f\"Overall validation watch_ratio@100: {weighted_watch_ratio:.4f}\")\n",
    "            \n",
    "            # Save validation metrics\n",
    "            metrics_df['params'] = param_str\n",
    "            if not os.path.exists(root + 'metrics'):\n",
    "                os.makedirs(root + 'metrics')\n",
    "            metrics_df.to_csv(root + f'metrics/validation_metrics_{param_str}.csv', index=False)\n",
    "        \n",
    "        # Save predictions\n",
    "        output_file = root + f'recommendations/w_clustering_{param_str}.csv' if not is_final else root + f'recommendations/final_w_clustering_{param_str}.csv'\n",
    "        watch_ratio_predictions_df.to_csv(output_file, index=False)\n",
    "        print(f'Predictions with segmentation saved to {output_file}')\n",
    "        \n",
    "        return weighted_watch_ratio\n",
    "    \n",
    "    # Train without clustering\n",
    "    if train_without_clustering:\n",
    "        _, predictions_df = train_and_predict(params, train_data, video_age_dict, validation_data=val_data)\n",
    "        \n",
    "        # Calculate validation metrics\n",
    "        val_predictions = predictions_df[\n",
    "            predictions_df['user_id'].isin(val_data['user_id']) & \n",
    "            predictions_df['video_id'].isin(val_data['video_id'])\n",
    "        ]\n",
    "        \n",
    "        # Calculate watch_ratio@100 for validation set\n",
    "        top_100_preds = val_predictions.nlargest(100, 'watch_ratio')\n",
    "        avg_watch_ratio = top_100_preds['watch_ratio'].mean()\n",
    "        print(f\"Validation watch_ratio@100: {avg_watch_ratio:.4f}\")\n",
    "        \n",
    "        # Save predictions\n",
    "        output_file = root + f'recommendations/wo_clustering_{param_str}.csv' if not is_final else root + f'recommendations/final_wo_clustering_{param_str}.csv'\n",
    "        predictions_df.to_csv(output_file, index=False)\n",
    "        print(f'Predictions without segmentation saved to {output_file}')\n",
    "        \n",
    "        return avg_watch_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hyperparameters: {'batch_size': 128, 'num_epochs': 10, 'lr': 0.0001, 'embedding_dim': 64, 'dropout': 0.0, 'decay': 0.01}\n",
      "----- Training for cluster 0 -----\n",
      "Initialising...\n",
      "Model moved to cpu\n",
      "Epoch [1/10], Loss: 0.4112\n",
      "Epoch [2/10], Loss: 0.3614\n",
      "Epoch [3/10], Loss: 0.3537\n",
      "Epoch [4/10], Loss: 0.3489\n",
      "Epoch [5/10], Loss: 0.3445\n",
      "Epoch [6/10], Loss: 0.3406\n",
      "Epoch [7/10], Loss: 0.3364\n",
      "Epoch [8/10], Loss: 0.3328\n",
      "Epoch [9/10], Loss: 0.3291\n",
      "Epoch [10/10], Loss: 0.3255\n",
      "Generating predictions...\n",
      "Complete!\n",
      "----- Training for cluster 1 -----\n",
      "Initialising...\n",
      "Model moved to cpu\n",
      "Epoch [1/10], Loss: 0.2193\n",
      "Epoch [2/10], Loss: 0.1793\n",
      "Epoch [3/10], Loss: 0.1742\n",
      "Epoch [4/10], Loss: 0.1715\n",
      "Epoch [5/10], Loss: 0.1691\n",
      "Epoch [6/10], Loss: 0.1670\n",
      "Epoch [7/10], Loss: 0.1651\n",
      "Epoch [8/10], Loss: 0.1632\n",
      "Epoch [9/10], Loss: 0.1614\n",
      "Epoch [10/10], Loss: 0.1601\n",
      "Generating predictions...\n",
      "Complete!\n",
      "----- Training for cluster 2 -----\n",
      "Initialising...\n",
      "Model moved to cpu\n",
      "Epoch [1/10], Loss: 0.2738\n",
      "Epoch [2/10], Loss: 0.2274\n",
      "Epoch [3/10], Loss: 0.2218\n",
      "Epoch [4/10], Loss: 0.2183\n",
      "Epoch [5/10], Loss: 0.2155\n",
      "Epoch [6/10], Loss: 0.2128\n",
      "Epoch [7/10], Loss: 0.2104\n",
      "Epoch [8/10], Loss: 0.2081\n",
      "Epoch [9/10], Loss: 0.2057\n",
      "Epoch [10/10], Loss: 0.2033\n",
      "Generating predictions...\n",
      "Complete!\n",
      "----- Training for cluster 3 -----\n",
      "Initialising...\n",
      "Model moved to cpu\n",
      "Epoch [1/10], Loss: 0.2790\n",
      "Epoch [2/10], Loss: 0.2324\n",
      "Epoch [3/10], Loss: 0.2271\n",
      "Epoch [4/10], Loss: 0.2235\n",
      "Epoch [5/10], Loss: 0.2206\n",
      "Epoch [6/10], Loss: 0.2182\n",
      "Epoch [7/10], Loss: 0.2156\n",
      "Epoch [8/10], Loss: 0.2132\n",
      "Epoch [9/10], Loss: 0.2108\n",
      "Epoch [10/10], Loss: 0.2086\n",
      "Generating predictions...\n",
      "Complete!\n",
      "Overall validation watch_ratio@100: 0.8706\n",
      "Predictions with segmentation saved to ../results/w_clustering_batch_size128_num_epochs10_lr0.0001_embedding_dim64_dropout0.0_decay0.01.csv\n",
      "New best parameters found! Watch_ratio@100: 0.8706\n",
      "Training with hyperparameters: {'batch_size': 128, 'num_epochs': 10, 'lr': 0.0001, 'embedding_dim': 64, 'dropout': 0.0, 'decay': 0.05}\n",
      "----- Training for cluster 0 -----\n",
      "Initialising...\n",
      "Model moved to cpu\n",
      "Epoch [1/10], Loss: 0.4112\n",
      "Epoch [2/10], Loss: 0.3614\n",
      "Epoch [3/10], Loss: 0.3537\n",
      "Epoch [4/10], Loss: 0.3489\n",
      "Epoch [5/10], Loss: 0.3445\n",
      "Epoch [6/10], Loss: 0.3406\n",
      "Epoch [7/10], Loss: 0.3364\n",
      "Epoch [8/10], Loss: 0.3328\n",
      "Epoch [9/10], Loss: 0.3291\n",
      "Epoch [10/10], Loss: 0.3255\n",
      "Generating predictions...\n",
      "Complete!\n",
      "----- Training for cluster 1 -----\n",
      "Initialising...\n",
      "Model moved to cpu\n",
      "Epoch [1/10], Loss: 0.2193\n",
      "Epoch [2/10], Loss: 0.1793\n",
      "Epoch [3/10], Loss: 0.1742\n",
      "Epoch [4/10], Loss: 0.1715\n",
      "Epoch [5/10], Loss: 0.1691\n",
      "Epoch [6/10], Loss: 0.1670\n",
      "Epoch [7/10], Loss: 0.1651\n",
      "Epoch [8/10], Loss: 0.1632\n",
      "Epoch [9/10], Loss: 0.1614\n",
      "Epoch [10/10], Loss: 0.1601\n",
      "Generating predictions...\n",
      "Complete!\n",
      "----- Training for cluster 2 -----\n",
      "Initialising...\n",
      "Model moved to cpu\n",
      "Epoch [1/10], Loss: 0.2738\n",
      "Epoch [2/10], Loss: 0.2274\n",
      "Epoch [3/10], Loss: 0.2218\n",
      "Epoch [4/10], Loss: 0.2183\n",
      "Epoch [5/10], Loss: 0.2155\n",
      "Epoch [6/10], Loss: 0.2128\n",
      "Epoch [7/10], Loss: 0.2104\n",
      "Epoch [8/10], Loss: 0.2081\n",
      "Epoch [9/10], Loss: 0.2057\n",
      "Epoch [10/10], Loss: 0.2033\n",
      "Generating predictions...\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'batch_size': [128, 256, 512],\n",
    "    'num_epochs': [10, 20, 30, 40],\n",
    "    'lr': [0.0001, 0.001, 0.01],\n",
    "    'embedding_dim': [64, 128, 256, 512],\n",
    "    'dropout': [0.0, 0.1, 0.3, 0.5],\n",
    "    'decay': [0.01, 0.05, 0.10]\n",
    "}\n",
    "\n",
    "# Generate all possible combinations of hyperparameters\n",
    "param_combinations = list(itertools.product(*hyperparameters.values()))\n",
    "\n",
    "# Train for each combination of hyperparameters\n",
    "best_params = None\n",
    "best_watch_ratio = 0\n",
    "\n",
    "for params in param_combinations:\n",
    "    params_dict = {key: val for key, val in zip(hyperparameters.keys(), params)}\n",
    "    print(f\"Training with hyperparameters: {params_dict}\")\n",
    "    \n",
    "    watch_ratio = train_by_cluster_and_without(params_dict, train_processed, video_age_dict, train_by_cluster=True, train_without_clustering=False, is_final=False)\n",
    "    \n",
    "    if watch_ratio > best_watch_ratio:\n",
    "        best_watch_ratio = watch_ratio\n",
    "        best_params = params_dict\n",
    "        print(f\"New best parameters found! Watch_ratio@100: {watch_ratio:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "print(f\"\\nTraining final model with best parameters: {best_params}\")\n",
    "train_by_cluster_and_without(best_params, train_processed, video_age_dict, train_by_cluster=True, train_without_clustering=False, is_final=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [TO BE COMPLETED] Evaluation metrics on validation set and choose final set of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned Model\n",
    "\n",
    "We have identified the set of parameters. We will therefore proceed to train the model using this set of hyperparameters on both the train and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining train and validation data\n",
    "Since the user's cluster as well as the top 3 regrouped categories are only present in the trian dataset, we need to merge it into the validation set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_categories_columns = ['user_id', 'cluster', 'News_Politics', 'Auto_Tech', 'Lifestyle', 'Sports_Fitness', 'Entertainment', 'Culture', 'Others']\n",
    "\n",
    "user_segments_and_categories = train[segmentation_categories_columns].drop_duplicates()\n",
    "\n",
    "# Merge into validation data\n",
    "val_merged = val.merge(user_segments_and_categories, on='user_id', how='left')\n",
    "\n",
    "# Combine train and validation data\n",
    "train_val = pd.concat([train, val_merged])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing combined data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to what we have done to the training data above, we get the new reference date and video ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date with validation: 2020-08-19\n"
     ]
    }
   ],
   "source": [
    "# Convert type to datetime\n",
    "train_val['time'] = pd.to_datetime(train_val['time'])\n",
    "\n",
    "# Assume current date is the next day of the last date\n",
    "CURRENT_DATE_VAL = train_val['time'].dt.date.max()\n",
    "\n",
    "# Just the date portion\n",
    "print(f'Current date with validation: {CURRENT_DATE_VAL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get video age for training + val data\n",
    "video_info_train_val = video_info[video_info['video_id'].isin(train_val['video_id'].unique())]\n",
    "video_info_train_val['video_age'] = (CURRENT_DATE_VAL - video_info_train_val['upload_dt'].dt.date).dt.days\n",
    "\n",
    "video_age_dict_new = video_info_train_val.set_index('video_id')['video_age'].to_dict()    # Convert to dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, one hot encoding of categorical variables as well as scaling of numerical variables is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode 'user_active_degree', 'time_period'\n",
    "train_val_processed = pd.get_dummies(train_val, columns=['user_active_degree', 'time_period'])\n",
    "\n",
    "# Remove the column for user_active_degree = UNKNOWN\n",
    "train_val_processed = train_val_processed.drop(columns=['user_active_degree_UNKNOWN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_new = StandardScaler()\n",
    "\n",
    "columns_to_scale = ['follow_user_num',\n",
    "       'fans_user_num', 'friend_user_num', 'register_days', 'video_duration',\n",
    "       'show_cnt', 'play_cnt', \n",
    "       'like_cnt', 'comment_cnt',\n",
    "       'share_cnt', 'follow_cnt', 'collect_cnt', \n",
    "       'total_connections',\n",
    "       'watch_frequency', \n",
    "       'count_afternoon_views', 'count_evening_views', 'count_midnight_views',\n",
    "       'count_morning_views', \n",
    "       'avg_daily_watch_time', \n",
    "       ]\n",
    "\n",
    "train_val_processed[columns_to_scale] = scaler_new.fit_transform(train_val_processed[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict with chosen parameters\n",
    "\n",
    "The model is then trained on the combined dataset, using the final set of parameters we have selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Training for cluster 0 -----\n",
      "Initialising...\n",
      "Model moved to cpu\n",
      "Epoch [1/20], Loss: 0.3898\n",
      "Epoch [2/20], Loss: 0.3540\n",
      "Epoch [3/20], Loss: 0.3437\n",
      "Epoch [4/20], Loss: 0.3380\n",
      "Epoch [5/20], Loss: 0.3343\n",
      "Epoch [6/20], Loss: 0.3315\n",
      "Epoch [7/20], Loss: 0.3291\n",
      "Epoch [8/20], Loss: 0.3265\n",
      "Epoch [9/20], Loss: 0.3235\n",
      "Epoch [10/20], Loss: 0.3204\n",
      "Epoch [11/20], Loss: 0.3171\n",
      "Epoch [12/20], Loss: 0.3138\n",
      "Epoch [13/20], Loss: 0.3097\n",
      "Epoch [14/20], Loss: 0.3058\n",
      "Epoch [15/20], Loss: 0.3015\n",
      "Epoch [16/20], Loss: 0.2976\n",
      "Epoch [17/20], Loss: 0.2929\n",
      "Epoch [18/20], Loss: 0.2890\n",
      "Epoch [19/20], Loss: 0.2846\n",
      "Epoch [20/20], Loss: 0.2804\n",
      "Generating predictions...\n",
      "Complete!\n",
      "----- Training for cluster 1 -----\n",
      "Initialising...\n",
      "Model moved to cpu\n",
      "Epoch [1/20], Loss: 0.2172\n",
      "Epoch [2/20], Loss: 0.1828\n",
      "Epoch [3/20], Loss: 0.1749\n",
      "Epoch [4/20], Loss: 0.1721\n",
      "Epoch [5/20], Loss: 0.1703\n",
      "Epoch [6/20], Loss: 0.1691\n",
      "Epoch [7/20], Loss: 0.1676\n",
      "Epoch [8/20], Loss: 0.1662\n",
      "Epoch [9/20], Loss: 0.1649\n",
      "Epoch [10/20], Loss: 0.1635\n",
      "Epoch [11/20], Loss: 0.1618\n",
      "Epoch [12/20], Loss: 0.1600\n",
      "Epoch [13/20], Loss: 0.1582\n",
      "Epoch [14/20], Loss: 0.1562\n",
      "Epoch [15/20], Loss: 0.1544\n",
      "Epoch [16/20], Loss: 0.1525\n",
      "Epoch [17/20], Loss: 0.1505\n",
      "Epoch [18/20], Loss: 0.1483\n",
      "Epoch [19/20], Loss: 0.1463\n",
      "Epoch [20/20], Loss: 0.1442\n",
      "Generating predictions...\n",
      "Complete!\n",
      "----- Training for cluster 2 -----\n",
      "Initialising...\n",
      "Model moved to cpu\n",
      "Epoch [1/20], Loss: 0.2617\n",
      "Epoch [2/20], Loss: 0.2309\n",
      "Epoch [3/20], Loss: 0.2223\n",
      "Epoch [4/20], Loss: 0.2181\n",
      "Epoch [5/20], Loss: 0.2159\n",
      "Epoch [6/20], Loss: 0.2142\n",
      "Epoch [7/20], Loss: 0.2128\n",
      "Epoch [8/20], Loss: 0.2113\n",
      "Epoch [9/20], Loss: 0.2094\n",
      "Epoch [10/20], Loss: 0.2074\n",
      "Epoch [11/20], Loss: 0.2050\n",
      "Epoch [12/20], Loss: 0.2028\n",
      "Epoch [13/20], Loss: 0.2000\n",
      "Epoch [14/20], Loss: 0.1974\n",
      "Epoch [15/20], Loss: 0.1944\n",
      "Epoch [16/20], Loss: 0.1916\n",
      "Epoch [17/20], Loss: 0.1883\n",
      "Epoch [18/20], Loss: 0.1857\n",
      "Epoch [19/20], Loss: 0.1828\n",
      "Epoch [20/20], Loss: 0.1802\n",
      "Generating predictions...\n",
      "Complete!\n",
      "----- Training for cluster 3 -----\n",
      "Initialising...\n",
      "Model moved to cpu\n",
      "Epoch [1/20], Loss: 0.2655\n",
      "Epoch [2/20], Loss: 0.2334\n",
      "Epoch [3/20], Loss: 0.2247\n",
      "Epoch [4/20], Loss: 0.2209\n",
      "Epoch [5/20], Loss: 0.2189\n",
      "Epoch [6/20], Loss: 0.2175\n",
      "Epoch [7/20], Loss: 0.2156\n",
      "Epoch [8/20], Loss: 0.2139\n",
      "Epoch [9/20], Loss: 0.2121\n",
      "Epoch [10/20], Loss: 0.2099\n",
      "Epoch [11/20], Loss: 0.2079\n",
      "Epoch [12/20], Loss: 0.2051\n",
      "Epoch [13/20], Loss: 0.2027\n",
      "Epoch [14/20], Loss: 0.1999\n",
      "Epoch [15/20], Loss: 0.1970\n",
      "Epoch [16/20], Loss: 0.1939\n",
      "Epoch [17/20], Loss: 0.1910\n",
      "Epoch [18/20], Loss: 0.1878\n",
      "Epoch [19/20], Loss: 0.1853\n",
      "Epoch [20/20], Loss: 0.1823\n",
      "Generating predictions...\n",
      "Complete!\n",
      "Predictions with segmentation saved to ./recommendations/results/final_w_clustering_batch_size512_num_epochs20_lr0.001_embedding_dim64_dropout0.3_decay0.01.csv\n",
      "----- Training -----\n",
      "Initialising...\n",
      "Model moved to cpu\n",
      "Epoch [1/20], Loss: 0.2537\n",
      "Epoch [2/20], Loss: 0.2315\n",
      "Epoch [3/20], Loss: 0.2288\n",
      "Epoch [4/20], Loss: 0.2273\n",
      "Epoch [5/20], Loss: 0.2263\n",
      "Epoch [6/20], Loss: 0.2251\n",
      "Epoch [7/20], Loss: 0.2238\n",
      "Epoch [8/20], Loss: 0.2225\n",
      "Epoch [9/20], Loss: 0.2208\n",
      "Epoch [10/20], Loss: 0.2191\n",
      "Epoch [11/20], Loss: 0.2173\n",
      "Epoch [12/20], Loss: 0.2153\n",
      "Epoch [13/20], Loss: 0.2132\n",
      "Epoch [14/20], Loss: 0.2112\n",
      "Epoch [15/20], Loss: 0.2091\n",
      "Epoch [16/20], Loss: 0.2072\n",
      "Epoch [17/20], Loss: 0.2052\n",
      "Epoch [18/20], Loss: 0.2032\n",
      "Epoch [19/20], Loss: 0.2015\n",
      "Epoch [20/20], Loss: 0.1997\n",
      "Generating predictions...\n",
      "Complete!\n",
      "Validation watch_ratio@100: 1.4748\n",
      "Predictions without segmentation saved to ./recommendations/final_wo_clustering_batch_size512_num_epochs20_lr0.001_embedding_dim64_dropout0.3_decay0.01.csv\n"
     ]
    }
   ],
   "source": [
    "tuned_params = {\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 20,\n",
    "    'lr': 0.001,\n",
    "    'embedding_dim': 64,\n",
    "    'dropout': 0.3,\n",
    "    'decay': 0.01\n",
    "}\n",
    "\n",
    "train_by_cluster_and_without(tuned_params, train_val_processed, video_age_dict_new, train_by_cluster=True, train_without_clustering=True, is_final=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
