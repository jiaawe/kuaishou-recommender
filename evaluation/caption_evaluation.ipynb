{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../'\n",
    "\n",
    "prediction_scores = pd.read_csv(root + 'recommendations/recommendations_caption_2.csv', index_col=0)\n",
    "prediction_scores_random = pd.read_csv(root + 'recommendations/recommendations_random.csv', index_col=0)\n",
    "joined_train_data = pd.read_csv(root + 'data_exports/joined_train_data.csv')\n",
    "joined_val_data = pd.read_csv(root + 'data_exports/joined_val_data.csv')\n",
    "\n",
    "video_data = pd.read_csv(root + 'data/kuairec_caption_category_translated.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>predicted_watch_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4.739207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>4.587039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>4.758113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>4.664595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>4.527781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12585121</th>\n",
       "      <td>7162</td>\n",
       "      <td>10723</td>\n",
       "      <td>4.786916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12585122</th>\n",
       "      <td>7162</td>\n",
       "      <td>10724</td>\n",
       "      <td>4.605312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12585123</th>\n",
       "      <td>7162</td>\n",
       "      <td>10725</td>\n",
       "      <td>4.621752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12585124</th>\n",
       "      <td>7162</td>\n",
       "      <td>10726</td>\n",
       "      <td>4.626483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12585125</th>\n",
       "      <td>7162</td>\n",
       "      <td>10727</td>\n",
       "      <td>4.691329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12585126 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  video_id  predicted_watch_ratio\n",
       "0              14         0               4.739207\n",
       "1              14         1               4.587039\n",
       "2              14         2               4.758113\n",
       "3              14         3               4.664595\n",
       "4              14         4               4.527781\n",
       "...           ...       ...                    ...\n",
       "12585121     7162     10723               4.786916\n",
       "12585122     7162     10724               4.605312\n",
       "12585123     7162     10725               4.621752\n",
       "12585124     7162     10726               4.626483\n",
       "12585125     7162     10727               4.691329\n",
       "\n",
       "[12585126 rows x 3 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename\n",
    "prediction_scores = prediction_scores.rename(columns={'watch_ratio': 'predicted_watch_ratio'})\n",
    "prediction_scores_random = prediction_scores_random.rename(columns={'watch_ratio': 'predicted_watch_ratio'})\n",
    "\n",
    "# Sort predictions\n",
    "prediction_scores = prediction_scores.sort_values(by=['user_id', 'video_id'])\n",
    "prediction_scores_random = prediction_scores_random.sort_values(by=['user_id', 'video_id'])\n",
    "prediction_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get user watch history\n",
    "\n",
    "We want to be able to filter out videos that the user has already watched. This is so that we recommend new videos instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_watch_history(data):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        data: DataFrame of user watch history. Must contain columns 'user_id' and 'video_id'.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary with user_id as key and a set of video_ids that the user has watched as value.\n",
    "    \"\"\"\n",
    "    watch_history_dict = defaultdict(set)\n",
    "    for user in data['user_id'].unique():\n",
    "        watch_history_dict[user] = set(data[data['user_id'] == user]['video_id'])\n",
    "    return watch_history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_watch_history = get_user_watch_history(joined_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting ground truth videos for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth(ground_truth_df, valid_videos, user_watch_history):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        ground_truth_df: DataFrame with the ground truth watch ratios.\n",
    "        videos_in_train_data: List of video_ids that are present in the training data.\n",
    "        user_watch_history: Dictionary with user_id as key and a list of video_ids that the user has watched as value.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with the ground truth watch ratios. It only contains videos that the user has not watched before, and videos that are present in training data.\n",
    "        The dataframe is sorted by user in ascending order and watch_ratio in descending order.\n",
    "    \"\"\"\n",
    "    ground_truth_new = pd.DataFrame(columns=['user_id', 'video_id', 'watch_ratio'])\n",
    "\n",
    "    for user in ground_truth_df['user_id'].unique():\n",
    "        user_ground_truth = ground_truth_df[ground_truth_df['user_id'] == user].copy()\n",
    "        user_ground_truth = user_ground_truth[~user_ground_truth['video_id'].isin(user_watch_history[user])]\n",
    "        user_ground_truth = user_ground_truth[user_ground_truth['video_id'].isin(valid_videos)]\n",
    "\n",
    "        ground_truth_new = pd.concat([ground_truth_new, user_ground_truth])\n",
    "\n",
    "    # Sort by watch_ratio in descending order\n",
    "    ground_truth_new = ground_truth_new.sort_values(by=['user_id', 'watch_ratio'], ascending=[True, False])\n",
    "    return ground_truth_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_in_train_data = set(joined_train_data['video_id'])\n",
    "\n",
    "ground_truth = get_ground_truth(joined_val_data[['user_id', 'video_id', 'watch_ratio']], videos_in_train_data, user_watch_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>watch_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>8766</td>\n",
       "      <td>3.318871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>14</td>\n",
       "      <td>8799</td>\n",
       "      <td>3.185954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>14</td>\n",
       "      <td>2735</td>\n",
       "      <td>2.598506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>14</td>\n",
       "      <td>4201</td>\n",
       "      <td>2.478148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>14</td>\n",
       "      <td>4015</td>\n",
       "      <td>2.319912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>14</td>\n",
       "      <td>7297</td>\n",
       "      <td>0.032396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>14</td>\n",
       "      <td>4021</td>\n",
       "      <td>0.032293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>14</td>\n",
       "      <td>4141</td>\n",
       "      <td>0.032250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>14</td>\n",
       "      <td>7461</td>\n",
       "      <td>0.029277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>14</td>\n",
       "      <td>8696</td>\n",
       "      <td>0.007218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>519 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id video_id  watch_ratio\n",
       "11       14     8766     3.318871\n",
       "702      14     8799     3.185954\n",
       "607      14     2735     2.598506\n",
       "602      14     4201     2.478148\n",
       "573      14     4015     2.319912\n",
       "..      ...      ...          ...\n",
       "131      14     7297     0.032396\n",
       "991      14     4021     0.032293\n",
       "180      14     4141     0.032250\n",
       "61       14     7461     0.029277\n",
       "243      14     8696     0.007218\n",
       "\n",
       "[519 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ground truth scores for user 14\n",
    "ground_truth[ground_truth['user_id'] == 14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting recommendations for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_recommendations(prediction_scores, user_watch_history):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        prediction_scores: DataFrame with the predicted watch_ratios.\n",
    "        user_watch_history: Dictionary with user_id as key and a list of video_ids that the user has watched as value.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with the recommendations for a specific user. It only contains videos that the user has not watched before.\n",
    "        The dataframe is sorted by user in ascending order and watch_ratio in descending order.\n",
    "    \"\"\"\n",
    "    recommendations_list = []\n",
    "    for user in tqdm(prediction_scores['user_id'].unique()):\n",
    "        user_recommendations = prediction_scores[prediction_scores['user_id'] == user].copy()\n",
    "        user_recommendations = user_recommendations[~user_recommendations['video_id'].isin(user_watch_history[user])]\n",
    "        \n",
    "        recommendations_list.append(user_recommendations)\n",
    "\n",
    "    # Concatenate all at once\n",
    "    recommendations_new = pd.concat(recommendations_list)\n",
    "\n",
    "    # Sort by prediction in descending order\n",
    "    recommendations_new = recommendations_new.sort_values(by=['user_id', 'predicted_watch_ratio'], ascending=[True, False])\n",
    "    return recommendations_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1411/1411 [00:10<00:00, 140.76it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1411/1411 [00:10<00:00, 139.52it/s]\n"
     ]
    }
   ],
   "source": [
    "recommendations = get_user_recommendations(prediction_scores, user_watch_history)\n",
    "recommendations_random = get_user_recommendations(prediction_scores_random, user_watch_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>predicted_watch_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>14</td>\n",
       "      <td>2449</td>\n",
       "      <td>4.822654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>14</td>\n",
       "      <td>2966</td>\n",
       "      <td>4.821256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>14</td>\n",
       "      <td>4989</td>\n",
       "      <td>4.821235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>14</td>\n",
       "      <td>488</td>\n",
       "      <td>4.815921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>14</td>\n",
       "      <td>3145</td>\n",
       "      <td>4.814930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7569</th>\n",
       "      <td>14</td>\n",
       "      <td>9140</td>\n",
       "      <td>4.753068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>14</td>\n",
       "      <td>3822</td>\n",
       "      <td>4.753046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7421</th>\n",
       "      <td>14</td>\n",
       "      <td>8992</td>\n",
       "      <td>4.753025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>14</td>\n",
       "      <td>2160</td>\n",
       "      <td>4.753019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7955</th>\n",
       "      <td>14</td>\n",
       "      <td>9526</td>\n",
       "      <td>4.753006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id video_id  predicted_watch_ratio\n",
       "1881      14     2449               4.822654\n",
       "2327      14     2966               4.821256\n",
       "4076      14     4989               4.821235\n",
       "368       14      488               4.815921\n",
       "2506      14     3145               4.814930\n",
       "...      ...      ...                    ...\n",
       "7569      14     9140               4.753068\n",
       "3113      14     3822               4.753046\n",
       "7421      14     8992               4.753025\n",
       "1737      14     2160               4.753019\n",
       "7955      14     9526               4.753006\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recommendations for user 14\n",
    "recommendations[recommendations['user_id'] == 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_grp = recommendations.groupby('user_id')\n",
    "reco_grp_random = recommendations_random.groupby('user_id')\n",
    "ground_truth_grp = ground_truth.groupby('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_for_user(k, user_id, df):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        k: The number of recommendations to return.\n",
    "        user_id: The user for which to get recommendations.\n",
    "        df: DataFrame containing the scores for all users, sorted by score in descending order.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with the top k scores.\n",
    "    \"\"\"\n",
    "    if isinstance(df, pd.core.groupby.generic.DataFrameGroupBy):\n",
    "        return df.get_group(user_id).head(k)\n",
    "\n",
    "    return df[df['user_id'] == user_id].head(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>predicted_watch_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>14</td>\n",
       "      <td>2449</td>\n",
       "      <td>4.822654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>14</td>\n",
       "      <td>2966</td>\n",
       "      <td>4.821256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>14</td>\n",
       "      <td>4989</td>\n",
       "      <td>4.821235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>14</td>\n",
       "      <td>488</td>\n",
       "      <td>4.815921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>14</td>\n",
       "      <td>3145</td>\n",
       "      <td>4.814930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6113</th>\n",
       "      <td>14</td>\n",
       "      <td>7485</td>\n",
       "      <td>4.812589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>14</td>\n",
       "      <td>3980</td>\n",
       "      <td>4.811253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3407</th>\n",
       "      <td>14</td>\n",
       "      <td>4318</td>\n",
       "      <td>4.810647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>14</td>\n",
       "      <td>1177</td>\n",
       "      <td>4.810339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>14</td>\n",
       "      <td>6664</td>\n",
       "      <td>4.810316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7905</th>\n",
       "      <td>14</td>\n",
       "      <td>9476</td>\n",
       "      <td>4.810308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6351</th>\n",
       "      <td>14</td>\n",
       "      <td>7723</td>\n",
       "      <td>4.809793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>14</td>\n",
       "      <td>3991</td>\n",
       "      <td>4.808955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6172</th>\n",
       "      <td>14</td>\n",
       "      <td>7544</td>\n",
       "      <td>4.808693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>14</td>\n",
       "      <td>263</td>\n",
       "      <td>4.808565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6961</th>\n",
       "      <td>14</td>\n",
       "      <td>8384</td>\n",
       "      <td>4.807788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7449</th>\n",
       "      <td>14</td>\n",
       "      <td>9020</td>\n",
       "      <td>4.807659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>14</td>\n",
       "      <td>498</td>\n",
       "      <td>4.807217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>14</td>\n",
       "      <td>6883</td>\n",
       "      <td>4.806890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>14</td>\n",
       "      <td>1902</td>\n",
       "      <td>4.806841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>14</td>\n",
       "      <td>1003</td>\n",
       "      <td>4.806075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>14</td>\n",
       "      <td>311</td>\n",
       "      <td>4.805421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6863</th>\n",
       "      <td>14</td>\n",
       "      <td>8264</td>\n",
       "      <td>4.805245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5870</th>\n",
       "      <td>14</td>\n",
       "      <td>7177</td>\n",
       "      <td>4.805214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5454</th>\n",
       "      <td>14</td>\n",
       "      <td>6613</td>\n",
       "      <td>4.805158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>14</td>\n",
       "      <td>825</td>\n",
       "      <td>4.804419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>14</td>\n",
       "      <td>2801</td>\n",
       "      <td>4.804297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7970</th>\n",
       "      <td>14</td>\n",
       "      <td>9542</td>\n",
       "      <td>4.804232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4940</th>\n",
       "      <td>14</td>\n",
       "      <td>6099</td>\n",
       "      <td>4.803656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>14</td>\n",
       "      <td>73</td>\n",
       "      <td>4.803598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4887</th>\n",
       "      <td>14</td>\n",
       "      <td>6046</td>\n",
       "      <td>4.803512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>14</td>\n",
       "      <td>1268</td>\n",
       "      <td>4.803011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>14</td>\n",
       "      <td>7250</td>\n",
       "      <td>4.802895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>14</td>\n",
       "      <td>918</td>\n",
       "      <td>4.802865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>14</td>\n",
       "      <td>9152</td>\n",
       "      <td>4.802742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>14</td>\n",
       "      <td>1663</td>\n",
       "      <td>4.802579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>14</td>\n",
       "      <td>1325</td>\n",
       "      <td>4.802204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>14</td>\n",
       "      <td>412</td>\n",
       "      <td>4.802127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7926</th>\n",
       "      <td>14</td>\n",
       "      <td>9497</td>\n",
       "      <td>4.801971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6610</th>\n",
       "      <td>14</td>\n",
       "      <td>7982</td>\n",
       "      <td>4.801969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>14</td>\n",
       "      <td>4122</td>\n",
       "      <td>4.801659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5662</th>\n",
       "      <td>14</td>\n",
       "      <td>6858</td>\n",
       "      <td>4.801409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5404</th>\n",
       "      <td>14</td>\n",
       "      <td>6563</td>\n",
       "      <td>4.801030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8239</th>\n",
       "      <td>14</td>\n",
       "      <td>9963</td>\n",
       "      <td>4.800984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5453</th>\n",
       "      <td>14</td>\n",
       "      <td>6612</td>\n",
       "      <td>4.800916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3685</th>\n",
       "      <td>14</td>\n",
       "      <td>4598</td>\n",
       "      <td>4.800492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>14</td>\n",
       "      <td>854</td>\n",
       "      <td>4.800371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>14</td>\n",
       "      <td>7470</td>\n",
       "      <td>4.800318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>14</td>\n",
       "      <td>201</td>\n",
       "      <td>4.800186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7201</th>\n",
       "      <td>14</td>\n",
       "      <td>8768</td>\n",
       "      <td>4.800062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id video_id  predicted_watch_ratio\n",
       "1881      14     2449               4.822654\n",
       "2327      14     2966               4.821256\n",
       "4076      14     4989               4.821235\n",
       "368       14      488               4.815921\n",
       "2506      14     3145               4.814930\n",
       "6113      14     7485               4.812589\n",
       "3199      14     3980               4.811253\n",
       "3407      14     4318               4.810647\n",
       "835       14     1177               4.810339\n",
       "5505      14     6664               4.810316\n",
       "7905      14     9476               4.810308\n",
       "6351      14     7723               4.809793\n",
       "3204      14     3991               4.808955\n",
       "6172      14     7544               4.808693\n",
       "214       14      263               4.808565\n",
       "6961      14     8384               4.807788\n",
       "7449      14     9020               4.807659\n",
       "374       14      498               4.807217\n",
       "5681      14     6883               4.806890\n",
       "1551      14     1902               4.806841\n",
       "662       14     1003               4.806075\n",
       "242       14      311               4.805421\n",
       "6863      14     8264               4.805245\n",
       "5870      14     7177               4.805214\n",
       "5454      14     6613               4.805158\n",
       "499       14      825               4.804419\n",
       "2162      14     2801               4.804297\n",
       "7970      14     9542               4.804232\n",
       "4940      14     6099               4.803656\n",
       "73        14       73               4.803598\n",
       "4887      14     6046               4.803512\n",
       "926       14     1268               4.803011\n",
       "5905      14     7250               4.802895\n",
       "578       14      918               4.802865\n",
       "7581      14     9152               4.802742\n",
       "1321      14     1663               4.802579\n",
       "983       14     1325               4.802204\n",
       "318       14      412               4.802127\n",
       "7926      14     9497               4.801971\n",
       "6610      14     7982               4.801969\n",
       "3249      14     4122               4.801659\n",
       "5662      14     6858               4.801409\n",
       "5404      14     6563               4.801030\n",
       "8239      14     9963               4.800984\n",
       "5453      14     6612               4.800916\n",
       "3685      14     4598               4.800492\n",
       "521       14      854               4.800371\n",
       "6098      14     7470               4.800318\n",
       "169       14      201               4.800186\n",
       "7201      14     8768               4.800062"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 50\n",
    "\n",
    "# Get top 50 ground truth and recommendations for user 14\n",
    "top_50_ground_truth_user_14 = get_top_k_for_user(k, 14, ground_truth)\n",
    "top_50_recommendations_user_14 = get_top_k_for_user(k, 14, reco_grp)\n",
    "top_50_recommendations_user_14_random = get_top_k_for_user(k, 14, reco_grp_random)\n",
    "\n",
    "# top_50_ground_truth_user_14\n",
    "top_50_recommendations_user_14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcuation of Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category-Aware NDCG@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_tally_at_k(recommendations, video_info):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        recommendations: DataFrame with the top k recommendations for a specific user.\n",
    "        video_info: DataFrame with information about the videos.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with the category as key and the number of videos in each category as value.\n",
    "    \"\"\"\n",
    "    tally = defaultdict(int)\n",
    "\n",
    "    for video_id in recommendations['video_id']:\n",
    "        category = video_info.loc[str(video_id)]['english_first_level_category_name']\n",
    "        tally[category] += 1\n",
    "    \n",
    "    return tally\n",
    "\n",
    "def get_category_ndcg_at_k(recommendations, ground_truth, video_info):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        recommendations: DataFrame with the top k video recommendations for a specific user.\n",
    "        ground_truth: DataFrame with the ground truth videos for a specific user.\n",
    "        video_info: DataFrame with information about the videos.\n",
    "\n",
    "    Returns:\n",
    "        NDCG score for the categories of the top k recommendations.\n",
    "    \"\"\"\n",
    "    cat_tally_reco = get_category_tally_at_k(recommendations, video_info)\n",
    "    cat_tally_gt = get_category_tally_at_k(ground_truth, video_info)\n",
    "\n",
    "    cat_tally_reco_adjusted = {}\n",
    "    for category in cat_tally_gt:\n",
    "        cat_tally_reco_adjusted[category] = cat_tally_reco.get(category, 0)\n",
    "        \n",
    "    return ndcg_score([list(cat_tally_gt.values())], [list(cat_tally_reco_adjusted.values())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071373787534083\n",
      "0.9331335159393579\n"
     ]
    }
   ],
   "source": [
    "# Get the category-aware NDCG@50 for user 14\n",
    "print(get_category_ndcg_at_k(top_50_recommendations_user_14, top_50_ground_truth_user_14, video_data))\n",
    "print(get_category_ndcg_at_k(top_50_recommendations_user_14_random, top_50_ground_truth_user_14, video_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average category-aware NDCG@50 for all users, and per cluster\n",
    "def get_average_ndcg_at_k(k, ground_truth, recommendations, video_info):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        k: The number of recommendations to return.\n",
    "        ground_truth: DataFrame with the ground truth watch ratios, sorted by descending watch_ratio.\n",
    "        recommendations: DataFrame with all video recommendations, sorted by descending predicted_watch_ratio.\n",
    "        video_info: DataFrame with information about the videos.\n",
    "\n",
    "    Returns:\n",
    "        The average category-aware NDCG@50 for all users.\n",
    "    \"\"\"\n",
    "    ndcg_scores = []\n",
    "\n",
    "    users_in_train = set(recommendations.groups.keys()) if isinstance(recommendations, pd.core.groupby.generic.DataFrameGroupBy) else set(recommendations['user_id'])\n",
    "    users_in_val = set(ground_truth['user_id'])\n",
    "\n",
    "    # Filter out users found in the validation set and not found in the training set. We cannot generate recommendations for these users since they do not exist in the training data\n",
    "    users_in_val = users_in_val.intersection(users_in_train)\n",
    "    for user_id in tqdm(users_in_val):\n",
    "        user_recommendations_top_k = get_top_k_for_user(k, user_id, recommendations)\n",
    "        user_ground_truth_top_k = get_top_k_for_user(k, user_id, ground_truth)\n",
    "\n",
    "        user_ndcg_score = get_category_ndcg_at_k(user_recommendations_top_k, user_ground_truth_top_k, video_info)\n",
    "\n",
    "        ndcg_scores.append(user_ndcg_score)\n",
    "\n",
    "    return np.mean(ndcg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1411/1411 [01:34<00:00, 14.91it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1411/1411 [01:35<00:00, 14.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall NDCG@50: 0.8224443169370017\n",
      "Overall NDCG@50 random: 0.8076224731772924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "overall_ndcg = get_average_ndcg_at_k(k, ground_truth, reco_grp, video_data)\n",
    "overall_ndcg_random = get_average_ndcg_at_k(k, ground_truth, reco_grp_random, video_data)\n",
    "\n",
    "print(f'Overall NDCG@{k}: {overall_ndcg}')\n",
    "print(f'Overall NDCG@{k} random: {overall_ndcg_random}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distinct Categories @ k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_distinct_categories_at_k(k, user_id, recommendations):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        k: The number of recommendations to return.\n",
    "        user_id: The user for which to get recommendations.\n",
    "        recommendations: DataFrame containing the scores for all users, sorted by score in descending order.\n",
    "        \n",
    "    Returns:\n",
    "        The number of distinct categories in the top k recommendations.\n",
    "    \"\"\"\n",
    "    top_k = get_top_k_for_user(k, user_id, recommendations)\n",
    "    categories = set()\n",
    "\n",
    "    for video_id in top_k['video_id']:\n",
    "        category = video_data.loc[str(video_id)]['english_first_level_category_name']\n",
    "        categories.add(category)\n",
    "    \n",
    "    return len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# Get Distinct Categories @ 50 for user 14\n",
    "print(get_user_distinct_categories_at_k(50, 14, recommendations))\n",
    "print(get_user_distinct_categories_at_k(50, 14, recommendations_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_distinct_categories_at_k(k, recommendations):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        k: The number of recommendations to return.\n",
    "        recommendations: DataFrame containing the scores for all users, sorted by score in descending order.\n",
    "    \n",
    "    Returns:\n",
    "        The overall average number of distinct categories in the top k recommendations, and a dictionary with the average number of distinct categories per cluster.\n",
    "    \"\"\"\n",
    "    all_distinct_categories = []\n",
    "\n",
    "    users_in_train = set(recommendations.groups.keys()) if isinstance(recommendations, pd.core.groupby.generic.DataFrameGroupBy) else set(recommendations['user_id'])\n",
    "    users_in_val = set(ground_truth['user_id'])\n",
    "\n",
    "    # Filter out users found in the validation set and not found in the training set. We cannot generate recommendations for these users since they do not exist in the training data\n",
    "    users_in_val = users_in_val.intersection(users_in_train)\n",
    "    for user_id in tqdm(users_in_val):\n",
    "        user_distinct_categories = get_user_distinct_categories_at_k(k, user_id, recommendations)\n",
    "\n",
    "        all_distinct_categories.append(user_distinct_categories)\n",
    "\n",
    "    return np.mean(all_distinct_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1411/1411 [00:19<00:00, 71.09it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1411/1411 [00:20<00:00, 69.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Distinct Categories @50: 13.360737065910701\n",
      "Overall Distinct Categories @50 random: 22.00850460666194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "overall_distinct_categories = get_average_distinct_categories_at_k(50, reco_grp)\n",
    "overall_distinct_categories_random = get_average_distinct_categories_at_k(50, reco_grp_random)\n",
    "\n",
    "print(f'Overall Distinct Categories @50: {overall_distinct_categories}')\n",
    "print(f'Overall Distinct Categories @50 random: {overall_distinct_categories_random}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average watch ratio @ k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_avg_watch_ratio_at_k(k, user_id, recommendations, watch_ratio_column, ground_truth):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        k: The number of recommendations to return.\n",
    "        user_id: The user for which to get recommendations.\n",
    "        recommendations: DataFrame containing the scores for all users, sorted by score in descending order.\n",
    "        \n",
    "    Returns:\n",
    "        The average watch_ratio in the top k recommendations.\n",
    "    \"\"\"\n",
    "    reco_subset = recommendations.get_group(user_id) if isinstance(recommendations, pd.core.groupby.generic.DataFrameGroupBy) else recommendations[recommendations['user_id'] == user_id]\n",
    "    ground_truth_subset = ground_truth.get_group(user_id) if isinstance(ground_truth, pd.core.groupby.generic.DataFrameGroupBy) else ground_truth[ground_truth['user_id'] == user_id]\n",
    "\n",
    "    video_ids = set(ground_truth_subset['video_id'])\n",
    "\n",
    "    top_k = set(reco_subset[reco_subset['video_id'].isin(video_ids)].head(k)['video_id'].tolist())\n",
    "\n",
    "    return np.mean(ground_truth_subset[ground_truth_subset['video_id'].isin(top_k)][watch_ratio_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.041527408845175\n",
      "0.99515572098966\n"
     ]
    }
   ],
   "source": [
    "# Get avg watch ratio @ 50 for user 14\n",
    "print(get_user_avg_watch_ratio_at_k(50, 14, reco_grp, 'watch_ratio', ground_truth_grp))\n",
    "print(get_user_avg_watch_ratio_at_k(50, 14, reco_grp_random, 'watch_ratio', ground_truth_grp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_watch_ratio_at_k(k, recommendations):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        k: The number of recommendations to return.\n",
    "        recommendations: DataFrame containing the scores for all users, sorted by score in descending order.\n",
    "        \n",
    "    Returns:\n",
    "        The overall average watch_ratio in the top k ground truth videos, a dictionary with the average watch_ratio per cluster, \n",
    "        the overall average predicted_watch_ratio in the top k recommendations, and a dictionary with the average predicted_watch_ratio per cluster.\n",
    "    \"\"\"\n",
    "    all_avg_watch_ratios_list = []\n",
    "\n",
    "    users_in_train = set(recommendations.groups.keys()) if isinstance(recommendations, pd.core.groupby.generic.DataFrameGroupBy) else set(recommendations['user_id'])\n",
    "    users_in_val = set(ground_truth['user_id'])\n",
    "\n",
    "    # Filter out users found in the validation set and not found in the training set. We cannot generate recommendations for these users since they do not exist in the training data\n",
    "    users_in_val = users_in_val.intersection(users_in_train)\n",
    "    for user_id in tqdm(users_in_val):\n",
    "        user_avg_watch_ratio = get_user_avg_watch_ratio_at_k(k, user_id, recommendations, 'watch_ratio', ground_truth_grp)\n",
    "\n",
    "        all_avg_watch_ratios_list.append(user_avg_watch_ratio)\n",
    "    \n",
    "    return np.mean(all_avg_watch_ratios_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1411/1411 [00:01<00:00, 1193.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1411/1411 [00:01<00:00, 1153.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Avg Watch Ratio @50: 0.8787895045090198\n",
      "Overall Avg Watch Ratio @50 random: 0.8428517616827994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "overall_avg_watch_ratio = get_avg_watch_ratio_at_k(50, reco_grp)\n",
    "overall_avg_watch_ratio_random = get_avg_watch_ratio_at_k(50, reco_grp_random)\n",
    "\n",
    "print(f'Overall Avg Watch Ratio @50: {overall_avg_watch_ratio}')\n",
    "print(f'Overall Avg Watch Ratio @50 random: {overall_avg_watch_ratio_random}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       caption     random\n",
      "ndcg                  0.822444   0.807622\n",
      "distinct_categories  13.360737  22.008505\n",
      "avg_watch_ratio       0.878790   0.842852\n"
     ]
    }
   ],
   "source": [
    "# combine all metrics\n",
    "metrics = {\n",
    "    'ndcg': overall_ndcg,\n",
    "    'distinct_categories': overall_distinct_categories,\n",
    "    'avg_watch_ratio': overall_avg_watch_ratio\n",
    "}\n",
    "\n",
    "metrics_random = {\n",
    "    'ndcg': overall_ndcg_random,\n",
    "    'distinct_categories': overall_distinct_categories_random,\n",
    "    'avg_watch_ratio': overall_avg_watch_ratio_random\n",
    "}\n",
    "\n",
    "# combine both metrics\n",
    "metrics = {\n",
    "    'caption': metrics,\n",
    "    'random': metrics_random\n",
    "}\n",
    "\n",
    "# print it as a nice dataframe\n",
    "print(pd.DataFrame(metrics))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision@k, Recall@k, F1Score@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_precision_recall_f1_at_k(k, user_id, recommendations, ground_truth, threshold):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        k: The number of recommendations to return.\n",
    "        user_id: The user for which to get recommendations.\n",
    "        recommendations: DataFrame containing the scores for all users, sorted by score in descending order.\n",
    "        ground_truth: DataFrame with the ground truth watch ratios.\n",
    "        threshold: The threshold for the watch ratio.\n",
    "    \n",
    "    Returns:\n",
    "        Precision, recall, and F1 score at k for a specific user.\n",
    "    \"\"\"\n",
    "    reco_subset = recommendations.get_group(user_id) if isinstance(recommendations, pd.core.groupby.generic.DataFrameGroupBy) else recommendations[recommendations['user_id'] == user_id]\n",
    "    ground_truth_subset = ground_truth.get_group(user_id) if isinstance(ground_truth, pd.core.groupby.generic.DataFrameGroupBy) else ground_truth[ground_truth['user_id'] == user_id]\n",
    "\n",
    "    video_ids = set(ground_truth_subset['video_id'])\n",
    "\n",
    "    reco_subset = reco_subset[reco_subset['video_id'].isin(video_ids)].head(k)\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "\n",
    "    for video_id in reco_subset['video_id']:\n",
    "        if video_id in ground_truth_subset['video_id'].values:\n",
    "            if ground_truth_subset[ground_truth_subset['video_id'] == video_id]['watch_ratio'].values[0] >= threshold:\n",
    "                # If the video is in top_k_ground_truth and watch ratio is above the threshold, it is a true positive\n",
    "                tp += 1\n",
    "            else:\n",
    "                # If the video is in top_k_ground_truth but watch ratio is below the threshold, it is a false positive\n",
    "                fp += 1\n",
    "                \n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall  = tp / np.sum(ground_truth_subset['watch_ratio'] >= threshold)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.726 0.9603174603174603 0.8268792710706149\n",
      "0.728 0.9629629629629629 0.8291571753986332\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "# Precision, recall, and F1 @ 500 for user 14\n",
    "precision, recall, f1 = get_user_precision_recall_f1_at_k(500, 14, reco_grp, ground_truth, threshold)\n",
    "precision_random, recall_random, f1_random = get_user_precision_recall_f1_at_k(500, 14, reco_grp_random, ground_truth, threshold)\n",
    "print(precision, recall, f1)\n",
    "print(precision_random, recall_random, f1_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_recall_f1_at_k(k, recommendations, ground_truth, threshold):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        k: The number of recommendations to return.\n",
    "        user_id: The user for which to get recommendations.\n",
    "        recommendations: DataFrame containing the scores for all users, sorted by score in descending order.\n",
    "        ground_truth: DataFrame with the ground truth watch ratios.\n",
    "        threshold: The threshold for the watch ratio.\n",
    "    \n",
    "    Returns:\n",
    "        The overall average precision, recall, and F1 score at k, and a dictionary with the average precision, recall, and F1 score per cluster.\n",
    "    \"\"\"\n",
    "    all_precision_list = []\n",
    "    all_recall_list = []\n",
    "    all_f1_list = []\n",
    "\n",
    "    users_in_train = set(recommendations.groups.keys()) if isinstance(recommendations, pd.core.groupby.generic.DataFrameGroupBy) else set(recommendations['user_id'])\n",
    "    users_in_val = set(ground_truth.groups.keys()) if isinstance(ground_truth, pd.core.groupby.generic.DataFrameGroupBy) else set(ground_truth['user_id'])\n",
    "\n",
    "    # Filter out users found in the validation set and not found in the training set. We cannot generate recommendations for these users since they do not exist in the training data\n",
    "    users_in_val = users_in_val.intersection(users_in_train)\n",
    "\n",
    "    for user_id in tqdm(users_in_val):\n",
    "        user_precision, user_recall, user_f1 = get_user_precision_recall_f1_at_k(k, user_id, recommendations, ground_truth, threshold)\n",
    "\n",
    "        all_precision_list.append(user_precision)\n",
    "        all_recall_list.append(user_recall)\n",
    "        all_f1_list.append(user_f1)\n",
    "    \n",
    "    return np.mean(all_precision_list), np.mean(all_recall_list), np.mean(all_f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1411/1411 [01:48<00:00, 13.02it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1411/1411 [01:47<00:00, 13.08it/s]\n"
     ]
    }
   ],
   "source": [
    "k = 500\n",
    "avg_precision, avg_recall, avg_f1 = get_precision_recall_f1_at_k(k, reco_grp, ground_truth_grp, threshold)\n",
    "avg_precision_random, avg_recall_random, avg_f1_random = get_precision_recall_f1_at_k(k, reco_grp_random, ground_truth_grp, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       caption     random\n",
      "ndcg                  0.822444   0.807622\n",
      "distinct_categories  13.360737  22.008505\n",
      "avg_watch_ratio       0.878790   0.842852\n",
      "precision             0.723177   0.723086\n",
      "recall                0.984918   0.984885\n",
      "f1                    0.827564   0.827500\n"
     ]
    }
   ],
   "source": [
    "# Merge all metrics\n",
    "metrics = {\n",
    "    'ndcg': overall_ndcg,\n",
    "    'distinct_categories': overall_distinct_categories,\n",
    "    'avg_watch_ratio': overall_avg_watch_ratio,\n",
    "    'precision': avg_precision,\n",
    "    'recall': avg_recall,\n",
    "    'f1': avg_f1\n",
    "}\n",
    "\n",
    "metrics_random = {\n",
    "    'ndcg': overall_ndcg_random,\n",
    "    'distinct_categories': overall_distinct_categories_random,\n",
    "    'avg_watch_ratio': overall_avg_watch_ratio_random,\n",
    "    'precision': avg_precision_random,\n",
    "    'recall': avg_recall_random,\n",
    "    'f1': avg_f1_random\n",
    "}\n",
    "\n",
    "# combine both metrics\n",
    "metrics = {\n",
    "    'caption': metrics,\n",
    "    'random': metrics_random\n",
    "}\n",
    "\n",
    "# print it as a nice dataframe\n",
    "print(pd.DataFrame(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
