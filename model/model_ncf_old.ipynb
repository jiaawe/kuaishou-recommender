{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the train, val, test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training data: 4054501\n",
      "Total number of validation data: 227390\n",
      "Total number of test data: 103558\n"
     ]
    }
   ],
   "source": [
    "root = 'KuaiRec 2.0/'\n",
    "\n",
    "# Training data\n",
    "train = pd.read_csv(root + \"joined_train_data_FE.csv\")\n",
    "\n",
    "# Validation data\n",
    "val = pd.read_csv(root + \"val_data.csv\")\n",
    "\n",
    "# Test data\n",
    "# test = pd.read_csv(root + \"test_data.csv\")\n",
    "\n",
    "print(f'Total number of training data: {len(train)}')\n",
    "print(f'Total number of validation data: {len(val)}')\n",
    "# print(f'Total number of test data: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime\n",
    "train['time'] = pd.to_datetime(train['time'])\n",
    "val['time'] = pd.to_datetime(val['time'])\n",
    "test['time'] = pd.to_datetime(test['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'video_id', 'time', 'watch_ratio', 'user_active_degree',\n",
       "       'is_lowactive_period', 'is_live_streamer', 'is_video_author',\n",
       "       'follow_user_num', 'fans_user_num', 'friend_user_num', 'register_days',\n",
       "       'author_id', 'video_type', 'video_tag_name', 'video_duration',\n",
       "       'show_cnt', 'play_cnt', 'play_duration', 'like_cnt', 'comment_cnt',\n",
       "       'share_cnt', 'follow_cnt', 'collect_cnt', 'manual_cover_text',\n",
       "       'caption', 'topic_tag', 'first_level_category_id',\n",
       "       'first_level_category_name', 'second_level_category_id',\n",
       "       'second_level_category_name', 'third_level_category_id',\n",
       "       'third_level_category_name', 'is_new_user', 'total_connections',\n",
       "       'is_content_creator', 'hour', 'day_of_week', 'watch_frequency',\n",
       "       'is_weekend_interaction', 'is_weekend', 'time_period',\n",
       "       'count_afternoon_views', 'count_evening_views', 'count_midnight_views',\n",
       "       'count_morning_views', 'avg_daily_watch_time', 'top_3_categories',\n",
       "       'avg_watch_ratio', 'total_likes_given', 'video_length_category',\n",
       "       'video_length_long', 'video_length_medium', 'engagement_rate',\n",
       "       'diversity_score', 'previous_time', 'time_since_last_interaction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter and sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['user_id', 'video_id', 'time', 'watch_ratio', 'user_active_degree',\n",
    "    #    'is_lowactive_period', 'is_live_streamer', 'is_video_author',\n",
    "       'follow_user_num', 'fans_user_num', 'friend_user_num', 'register_days',\n",
    "    #    'author_id', 'video_type', \n",
    "      #  'video_tag_name', \n",
    "       'video_duration',\n",
    "       'show_cnt', 'play_cnt', 'play_duration', 'like_cnt', 'comment_cnt',\n",
    "    #    'share_cnt', 'follow_cnt', 'collect_cnt', 'manual_cover_text',\n",
    "    #    'caption', 'topic_tag', \n",
    "       'first_level_category_id',\n",
    "    #    'first_level_category_name', \n",
    "       'second_level_category_id',\n",
    "    #    'second_level_category_name', \n",
    "       'third_level_category_id',\n",
    "    #    'third_level_category_name', \n",
    "       'is_new_user', 'total_connections',\n",
    "    #    'is_content_creator', 'hour', 'day_of_week', \n",
    "       'watch_frequency',\n",
    "       'is_weekend_interaction', 'is_weekend', \n",
    "      #  'time_period',\n",
    "       'count_afternoon_views', 'count_evening_views', 'count_midnight_views',\n",
    "       'count_morning_views', 'avg_daily_watch_time', 'top_3_categories',\n",
    "       'avg_watch_ratio', 'total_likes_given', \n",
    "    #    'video_length_category', 'video_length_long', 'video_length_medium', \n",
    "       'engagement_rate',\n",
    "    #    'diversity_score', 'previous_time', 'time_since_last_interaction'\n",
    "       ]\n",
    "filtered_train = train[columns]\n",
    "\n",
    "# Sort by user_id and time\n",
    "filtered_train = filtered_train.sort_values(by=['user_id', 'time'], ascending=True)\n",
    "val = val.sort_values(by=['user_id', 'time'], ascending=True)\n",
    "test = test.sort_values(by=['user_id', 'time'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique users and items from the training data\n",
    "train_users = set(filtered_train['user_id'].unique())\n",
    "train_items = set(filtered_train['video_id'].unique())\n",
    "\n",
    "# Filter the validation set\n",
    "filtered_val = val[\n",
    "    val['user_id'].isin(train_users) & val['video_id'].isin(train_items)\n",
    "]\n",
    "\n",
    "# Filter the test set\n",
    "filtered_test = test[\n",
    "    test['user_id'].isin(train_users) & test['video_id'].isin(train_items)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chong\\AppData\\Local\\Temp\\ipykernel_2032\\959229793.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_val['user_id'] = user_encoder.transform(filtered_val['user_id'])\n",
      "C:\\Users\\chong\\AppData\\Local\\Temp\\ipykernel_2032\\959229793.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_val['video_id'] = video_encoder.transform(filtered_val['video_id'])\n",
      "C:\\Users\\chong\\AppData\\Local\\Temp\\ipykernel_2032\\959229793.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_test['user_id'] = user_encoder.transform(filtered_test['user_id'])\n",
      "C:\\Users\\chong\\AppData\\Local\\Temp\\ipykernel_2032\\959229793.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_test['video_id'] = video_encoder.transform(filtered_test['video_id'])\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "user_encoder = LabelEncoder()\n",
    "video_encoder = LabelEncoder()\n",
    "\n",
    "filtered_train['user_id'] = user_encoder.fit_transform(filtered_train['user_id'])\n",
    "filtered_train['video_id'] = video_encoder.fit_transform(filtered_train['video_id'])\n",
    "\n",
    "filtered_val['user_id'] = user_encoder.transform(filtered_val['user_id'])\n",
    "filtered_val['video_id'] = video_encoder.transform(filtered_val['video_id'])\n",
    "\n",
    "filtered_test['user_id'] = user_encoder.transform(filtered_test['user_id'])\n",
    "filtered_test['video_id'] = video_encoder.transform(filtered_test['video_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose random 15000 samples from the training data\n",
    "filtered_train2 = filtered_train.sample(n=15000, random_state=1)\n",
    "\n",
    "train_users = set(filtered_train2['user_id'].unique())\n",
    "train_items = set(filtered_train2['video_id'].unique())\n",
    "\n",
    "# Filter the validation set\n",
    "filtered_val = val[\n",
    "    val['user_id'].isin(train_users) & val['video_id'].isin(train_items)\n",
    "]\n",
    "\n",
    "# Filter the test set\n",
    "filtered_test = test[\n",
    "    test['user_id'].isin(train_users) & test['video_id'].isin(train_items)\n",
    "]\n",
    "\n",
    "len(filtered_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n",
      "14562\n",
      "5049\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_train2))\n",
    "print(len(filtered_val))\n",
    "print(len(filtered_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KuaiShouDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        return {\n",
    "            'user_id': torch.tensor(row['user_id'], dtype=torch.long),\n",
    "            'video_id': torch.tensor(row['video_id'], dtype=torch.long),\n",
    "            'time': torch.tensor(row['time'].timestamp(), dtype=torch.float),  # datetime to float (seconds since epoch)\n",
    "            'watch_ratio': torch.tensor(row['watch_ratio'], dtype=torch.float),\n",
    "            'follow_user_num': torch.tensor(row['follow_user_num'], dtype=torch.long),\n",
    "            'fans_user_num': torch.tensor(row['fans_user_num'], dtype=torch.long),\n",
    "            'friend_user_num': torch.tensor(row['friend_user_num'], dtype=torch.long),\n",
    "            'register_days': torch.tensor(row['register_days'], dtype=torch.float),\n",
    "            'video_duration': torch.tensor(row['video_duration'], dtype=torch.float),\n",
    "            'show_cnt': torch.tensor(row['show_cnt'], dtype=torch.long),\n",
    "            'play_cnt': torch.tensor(row['play_cnt'], dtype=torch.long),\n",
    "            'play_duration': torch.tensor(row['play_duration'], dtype=torch.float),\n",
    "            'like_cnt': torch.tensor(row['like_cnt'], dtype=torch.long),\n",
    "            'comment_cnt': torch.tensor(row['comment_cnt'], dtype=torch.long),\n",
    "            'first_level_category_id': torch.tensor(row['first_level_category_id'], dtype=torch.long),\n",
    "            'second_level_category_id': torch.tensor(row['second_level_category_id'], dtype=torch.long),\n",
    "            'third_level_category_id': torch.tensor(row['third_level_category_id'], dtype=torch.long),\n",
    "            'is_new_user': torch.tensor(row['is_new_user'], dtype=torch.long),\n",
    "            'total_connections': torch.tensor(row['total_connections'], dtype=torch.long),\n",
    "            'watch_frequency': torch.tensor(row['watch_frequency'], dtype=torch.float),\n",
    "            'is_weekend_interaction': torch.tensor(row['is_weekend_interaction'], dtype=torch.long),\n",
    "            'is_weekend': torch.tensor(row['is_weekend'], dtype=torch.long),\n",
    "            'count_afternoon_views': torch.tensor(row['count_afternoon_views'], dtype=torch.long),\n",
    "            'count_evening_views': torch.tensor(row['count_evening_views'], dtype=torch.long),\n",
    "            'count_midnight_views': torch.tensor(row['count_midnight_views'], dtype=torch.long),\n",
    "            'count_morning_views': torch.tensor(row['count_morning_views'], dtype=torch.long),\n",
    "            'avg_daily_watch_time': torch.tensor(row['avg_daily_watch_time'], dtype=torch.float),\n",
    "            # 'top_3_categories': torch.tensor(row['top_3_categories'], dtype=torch.long),\n",
    "            'avg_watch_ratio': torch.tensor(row['avg_watch_ratio'], dtype=torch.float),\n",
    "            'total_likes_given': torch.tensor(row['total_likes_given'], dtype=torch.long),\n",
    "            'engagement_rate': torch.tensor(row['engagement_rate'], dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoad\n",
    "# dataset_train = KuaiShouDataset(filtered_train)\n",
    "dataset_train = KuaiShouDataset(filtered_train2)\n",
    "dataset_val = KuaiShouDataset(filtered_val)\n",
    "dataset_test = KuaiShouDataset(filtered_test)\n",
    "\n",
    "# Set the batch size and other DataLoader parameters\n",
    "batch_size = 512\n",
    "\n",
    "# Initialise the DataLoader\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Factorisation Machine architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['time', \n",
    "            # 'user_active_degree',\n",
    "    #    'is_lowactive_period', 'is_live_streamer', 'is_video_author',\n",
    "       'follow_user_num', 'fans_user_num', 'friend_user_num', 'register_days',\n",
    "    #    'author_id', 'video_type', \n",
    "      #  'video_tag_name', \n",
    "       'video_duration',\n",
    "       'show_cnt', 'play_cnt', 'play_duration', 'like_cnt', 'comment_cnt',\n",
    "    #    'share_cnt', 'follow_cnt', 'collect_cnt', 'manual_cover_text',\n",
    "    #    'caption', 'topic_tag', \n",
    "       'first_level_category_id',\n",
    "    #    'first_level_category_name', \n",
    "       'second_level_category_id',\n",
    "    #    'second_level_category_name', \n",
    "       'third_level_category_id',\n",
    "    #    'third_level_category_name', \n",
    "       'is_new_user', 'total_connections',\n",
    "    #    'is_content_creator', 'hour', 'day_of_week', \n",
    "       'watch_frequency',\n",
    "       'is_weekend_interaction', 'is_weekend', \n",
    "      #  'time_period',\n",
    "       'count_afternoon_views', 'count_evening_views', 'count_midnight_views',\n",
    "       'count_morning_views', 'avg_daily_watch_time', \n",
    "      #  'top_3_categories',\n",
    "       'avg_watch_ratio', 'total_likes_given', \n",
    "    #    'video_length_category', 'video_length_long', 'video_length_medium', \n",
    "       'engagement_rate',\n",
    "    #    'diversity_score', 'previous_time', 'time_since_last_interaction'\n",
    "       ]\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GMF and MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFM_MLP(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, mlp_hidden_layers, num_additional_features):\n",
    "        super(NFM_MLP, self).__init__()\n",
    "\n",
    "        # GMF Components\n",
    "        self.user_embeddings_gmf = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embeddings_gmf = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        # MLP Components\n",
    "        self.user_embeddings_mlp = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embeddings_mlp = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        # Calculate input size for MLP based on embedding and additional features\n",
    "        input_size = 2 * embedding_dim + num_additional_features  # Adjusted input size\n",
    "\n",
    "        # Create MLP layers dynamically from the hidden layer sizes list\n",
    "        self.mlp_layers = nn.ModuleList()\n",
    "        for hidden_size in mlp_hidden_layers:\n",
    "            self.mlp_layers.append(nn.Linear(input_size, hidden_size))\n",
    "            input_size = hidden_size  # Update input size for the next layer\n",
    "\n",
    "        # Final combined layers\n",
    "        self.fc1_combined = nn.Linear(embedding_dim + mlp_hidden_layers[-1], num_items)\n",
    "        self.fc2_combined = nn.Linear(num_items, 1) # Output size set to num_items\n",
    "\n",
    "    def forward(self, user_id, item_id, additional_features):\n",
    "        # GMF: Generalized Matrix Factorization\n",
    "        user_emb_gmf = self.user_embeddings_gmf(user_id)\n",
    "        item_emb_gmf = self.item_embeddings_gmf(item_id)\n",
    "        gmf_output = user_emb_gmf * item_emb_gmf  # Element-wise multiplication\n",
    "\n",
    "        # MLP: Multi-Layer Perceptron\n",
    "        user_emb_mlp = self.user_embeddings_mlp(user_id)\n",
    "        item_emb_mlp = self.item_embeddings_mlp(item_id)\n",
    "        mlp_input = torch.cat([user_emb_mlp, item_emb_mlp, additional_features], dim=-1)\n",
    "\n",
    "        # Pass through the dynamic MLP layers\n",
    "        mlp_output = mlp_input  # Start with concatenated input\n",
    "        for layer in self.mlp_layers:\n",
    "            mlp_output = torch.relu(layer(mlp_output))\n",
    "\n",
    "        # Combine GMF and MLP outputs\n",
    "        combined_input = torch.cat([gmf_output, mlp_output], dim=-1)\n",
    "        combined_output = torch.relu(self.fc1_combined(combined_input))\n",
    "        combined_output = self.fc2_combined(combined_output)  # Final output layer\n",
    "\n",
    "        return combined_output.squeeze()  # Remove extra dimension for output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GMF and CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NFM_CNN(nn.Module):\n",
    "#     def __init__(self, num_users, num_items, embedding_dim, cnn_hidden_layers):\n",
    "#         super(NFM_CNN, self).__init__()\n",
    "\n",
    "#         # GMF Components\n",
    "#         self.user_embeddings_gmf = nn.Embedding(num_users, embedding_dim)\n",
    "#         self.item_embeddings_gmf = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "#         # CNN Components\n",
    "#         self.user_embeddings_cnn = nn.Embedding(num_users, embedding_dim)\n",
    "#         self.item_embeddings_cnn = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "#         # Create CNN layers dynamically from the hidden layer sizes list\n",
    "#         self.cnn_layers = nn.ModuleList()\n",
    "#         input_channels = 1  # Since we will use 1D convolutions\n",
    "#         input_size = 2 * embedding_dim  # Input size for CNN\n",
    "#         for hidden_size in cnn_hidden_layers:\n",
    "#             self.cnn_layers.append(nn.Conv1d(input_channels, hidden_size, kernel_size=3, padding=1))\n",
    "#             input_channels = hidden_size  # Update input channels for the next layer\n",
    "\n",
    "#         # Final combined layers\n",
    "#         self.fc1_combined = nn.Linear(embedding_dim + cnn_hidden_layers[-1], 128)\n",
    "#         self.fc2_combined = nn.Linear(128, 1)\n",
    "\n",
    "#     def forward(self, user_id, item_id):\n",
    "#         # GMF: Generalized Matrix Factorization\n",
    "#         user_emb_gmf = self.user_embeddings_gmf(user_id)\n",
    "#         item_emb_gmf = self.item_embeddings_gmf(item_id)\n",
    "#         gmf_output = user_emb_gmf * item_emb_gmf  # Element-wise multiplication\n",
    "\n",
    "#         # CNN: Convolutional Neural Network\n",
    "#         user_emb_cnn = self.user_embeddings_cnn(user_id)\n",
    "#         item_emb_cnn = self.item_embeddings_cnn(item_id)\n",
    "#         cnn_input = torch.cat([user_emb_cnn, item_emb_cnn], dim=-1).unsqueeze(1)  # Add channel dimension\n",
    "\n",
    "#         # Pass through the dynamic CNN layers\n",
    "#         cnn_output = cnn_input\n",
    "#         for layer in self.cnn_layers:\n",
    "#             cnn_output = torch.relu(layer(cnn_output))\n",
    "#             cnn_output = torch.max_pool1d(cnn_output, kernel_size=2)  # Apply max pooling\n",
    "\n",
    "#         # Flatten the CNN output\n",
    "#         cnn_output = cnn_output.view(cnn_output.size(0), -1)\n",
    "\n",
    "#         # Combine GMF and CNN outputs\n",
    "#         combined_input = torch.cat([gmf_output, cnn_output], dim=-1)\n",
    "#         combined_output = F.relu(self.fc1_combined(combined_input))\n",
    "#         combined_output = self.fc2_combined(combined_output)  # Final output layer\n",
    "\n",
    "#         return combined_output.squeeze()  # Remove extra dimension for output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GMF and MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 9469384465034772480.0000\n",
      "Epoch [2/10], Loss: 235268223891668992.0000\n",
      "Epoch [3/10], Loss: 25701601842823168.0000\n",
      "Epoch [4/10], Loss: 293813780217856.0000\n",
      "Epoch [5/10], Loss: 184321440743424.0000\n",
      "Epoch [6/10], Loss: 78267214200832.0000\n",
      "Epoch [7/10], Loss: 40721188913152.0000\n",
      "Epoch [8/10], Loss: 24082416402432.0000\n",
      "Epoch [9/10], Loss: 13983483428864.0000\n",
      "Epoch [10/10], Loss: 9771708055552.0000\n"
     ]
    }
   ],
   "source": [
    "# Define model parameters\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_items = len(video_encoder.classes_)\n",
    "EMBEDDING_DIM = 64\n",
    "MLP_HIDDEN_LAYERS = [16, 8]  # Custom MLP hidden layer sizes\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Instantiate the model\n",
    "num_additional_features = len(features) # Number of features excluding user_id and video_id, watch_ratio\n",
    "model = NFM_MLP(num_users, num_items, EMBEDDING_DIM, MLP_HIDDEN_LAYERS, num_additional_features)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for batch in train_loader:\n",
    "        user_id = batch['user_id']\n",
    "        video_id = batch['video_id']\n",
    "        ratio = batch['watch_ratio'].float()\n",
    "\n",
    "        # Gather additional features\n",
    "        additional_features = torch.cat([\n",
    "            batch['time'].unsqueeze(1),\n",
    "            batch['follow_user_num'].unsqueeze(1),\n",
    "            batch['fans_user_num'].unsqueeze(1),\n",
    "            batch['friend_user_num'].unsqueeze(1),\n",
    "            batch['register_days'].unsqueeze(1),\n",
    "            batch['video_duration'].unsqueeze(1),\n",
    "            batch['show_cnt'].unsqueeze(1),\n",
    "            batch['play_cnt'].unsqueeze(1),\n",
    "            batch['play_duration'].unsqueeze(1),\n",
    "            batch['like_cnt'].unsqueeze(1),\n",
    "            batch['comment_cnt'].unsqueeze(1),\n",
    "            batch['first_level_category_id'].unsqueeze(1),\n",
    "            batch['second_level_category_id'].unsqueeze(1),\n",
    "            batch['third_level_category_id'].unsqueeze(1),\n",
    "            batch['is_new_user'].unsqueeze(1),\n",
    "            batch['total_connections'].unsqueeze(1),\n",
    "            batch['watch_frequency'].unsqueeze(1),\n",
    "            batch['is_weekend_interaction'].unsqueeze(1),\n",
    "            batch['is_weekend'].unsqueeze(1),\n",
    "            batch['count_afternoon_views'].unsqueeze(1),\n",
    "            batch['count_evening_views'].unsqueeze(1),\n",
    "            batch['count_midnight_views'].unsqueeze(1),\n",
    "            batch['count_morning_views'].unsqueeze(1),\n",
    "            batch['avg_daily_watch_time'].unsqueeze(1),\n",
    "            batch['avg_watch_ratio'].unsqueeze(1),\n",
    "            batch['total_likes_given'].unsqueeze(1),\n",
    "            batch['engagement_rate'].unsqueeze(1),\n",
    "        ], dim=-1)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(user_id, video_id, additional_features)\n",
    "        loss = criterion(outputs, ratio)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss at the end of each epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[200], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 4\u001b[0m     user_id \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_train2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     video_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(filtered_train2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m     ratio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(filtered_train2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwatch_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n",
      "\u001b[1;31mValueError\u001b[0m: could not determine the shape of object type 'Series'"
     ]
    }
   ],
   "source": [
    "# Get recommendations for user 0\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    user_id = torch.tensor(filtered_train2['user_id'])\n",
    "    video_id = torch.tensor(filtered_train2['video_id'])\n",
    "    ratio = torch.tensor(filtered_train2['watch_ratio'].values, dtype=torch.float)\n",
    "\n",
    "    # Gather additional features\n",
    "    additional_features = torch.cat([\n",
    "        filtered_train2['time'].unsqueeze(1),\n",
    "        filtered_train2['follow_user_num'].unsqueeze(1),\n",
    "        filtered_train2['fans_user_num'].unsqueeze(1),\n",
    "        filtered_train2['friend_user_num'].unsqueeze(1),\n",
    "        filtered_train2['register_days'].unsqueeze(1),\n",
    "        filtered_train2['video_duration'].unsqueeze(1),\n",
    "        filtered_train2['show_cnt'].unsqueeze(1),\n",
    "        filtered_train2['play_cnt'].unsqueeze(1),\n",
    "        filtered_train2['play_duration'].unsqueeze(1),\n",
    "        filtered_train2['like_cnt'].unsqueeze(1),\n",
    "        filtered_train2['comment_cnt'].unsqueeze(1),\n",
    "        filtered_train2['first_level_category_id'].unsqueeze(1),\n",
    "        filtered_train2['second_level_category_id'].unsqueeze(1),\n",
    "        filtered_train2['third_level_category_id'].unsqueeze(1),\n",
    "        filtered_train2['is_new_user'].unsqueeze(1),\n",
    "        filtered_train2['total_connections'].unsqueeze(1),\n",
    "        filtered_train2['watch_frequency'].unsqueeze(1),\n",
    "        filtered_train2['is_weekend_interaction'].unsqueeze(1),\n",
    "        filtered_train2['is_weekend'].unsqueeze(1),\n",
    "        filtered_train2['count_afternoon_views'].unsqueeze(1),\n",
    "        filtered_train2['count_evening_views'].unsqueeze(1),\n",
    "        filtered_train2['count_midnight_views'].unsqueeze(1),\n",
    "        filtered_train2['count_morning_views'].unsqueeze(1),\n",
    "        filtered_train2['avg_daily_watch_time'].unsqueeze(1),\n",
    "        filtered_train2['avg_watch_ratio'].unsqueeze(1),\n",
    "        filtered_train2['total_likes_given'].unsqueeze(1),\n",
    "        filtered_train2['engagement_rate'].unsqueeze(1),\n",
    "    ], dim=-1)\n",
    "\n",
    "    scores = model(user_id, video_id, additional_features)  # Get output scores\n",
    "    top_n_indices = scores.argsort(descending=True)[:20]  # Get indices of top N scores\n",
    "    top_n_videos = video_id[top_n_indices]  # Get top N video IDs based on sorted scores\n",
    "\n",
    "    print(f'Top 20 recommended videos for user 0: {top_n_videos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GMP and MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # After training, evaluate on the test set\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "# test_loss = 0\n",
    "# with torch.no_grad():  # Disable gradient calculation for testing\n",
    "#     for test_batch in test_loader:\n",
    "#         user_id_test = test_batch['user_id']\n",
    "#         video_id_test = test_batch['video_id']\n",
    "#         rating_test = test_batch['watch_ratio'].float()  # Test target\n",
    "\n",
    "#         test_outputs = model(user_id_test, video_id_test)\n",
    "#         test_loss += criterion(test_outputs, rating_test).item()\n",
    "\n",
    "# # Calculate average test loss\n",
    "# test_loss /= len(test_loader)\n",
    "# print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
