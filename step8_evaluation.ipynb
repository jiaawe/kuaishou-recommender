{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your root directory below. Make sure the `/data`, `/data_exports` and `/recommendations` folders are uploaded and is situated in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust your root directory\n",
    "root = '/content/drive/MyDrive/KuaiRec/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import eval_fns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, we have eight sets of predictions - 2 per model. One set is generated from only the training set and is to be evaluated against the validation set, while the other is generated after training on both the training and validation sets and to be evaluated on the final testing set. Hyperparameters for the models were chosen based on the validation set, and the final predictions are generated using these hyperparameters. The test set represents the final unseen data, and the performance of the models on this set is the most important.\n",
    "\n",
    "There is also an additional set of predictions from the NCF model, trained on the train and validation data, without user segmentation. This will be evaluated on the test dataset and compared to the performance of the NCF model with user segmentation. With this analysis, we want to see how much does the user segmentation contribute to the NCF model overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './'\n",
    "\n",
    "# Predictions to be tested on the validation set\n",
    "prediction_scores_caption_on_val = pd.read_csv(root + 'recommendations/recommendations_caption_val_full.csv')\n",
    "prediction_scores_ncf_on_val = pd.read_csv(root + 'recommendations/w_clustering_batch_size512_num_epochs20_lr0.001_embedding_dim64_dropout0.3_decay0.01.csv')\n",
    "prediction_scores_hybrid_on_val = pd.read_csv(root + 'recommendations/recommendations_hybrid_val_full.csv')\n",
    "prediction_scores_random_on_val = pd.read_csv(root + 'recommendations/recommendations_random_val_full.csv')\n",
    "\n",
    "# Predictions to be tested on the test set\n",
    "prediction_scores_caption_on_test = pd.read_csv(root + 'recommendations/recommendations_caption_test_full.csv')\n",
    "prediction_scores_ncf_on_test = pd.read_csv(root + 'recommendations/final_w_clustering_batch_size512_num_epochs20_lr0.001_embedding_dim64_dropout0.3_decay0.01.csv')\n",
    "prediction_scores_hybrid_on_test = pd.read_csv(root + 'recommendations/recommendations_hybrid_test_full.csv')\n",
    "prediction_scores_random_on_test = pd.read_csv(root + 'recommendations/recommendations_random_test_full.csv')\n",
    "\n",
    "prediction_scores_ncf_on_test_without_clustering = pd.read_csv(root + 'recommendations/final_wo_clustering_batch_size512_num_epochs20_lr0.001_embedding_dim64_dropout0.3_decay0.01.csv')\n",
    "\n",
    "# Obtain the ground truth watch ratios from data\n",
    "joined_train_data = pd.read_csv(root + 'data_exports/joined_train_data.csv')\n",
    "joined_val_data = pd.read_csv(root + 'data_exports/joined_val_data.csv')\n",
    "joined_test_data = pd.read_csv(root + 'data_exports/joined_test_data.csv')\n",
    "\n",
    "joined_train_val_data = pd.concat([joined_train_data, joined_val_data])\n",
    "\n",
    "# Load the video data in order to get the video categories\n",
    "video_data = pd.read_csv(root + 'data/kuairec_caption_category_translated.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename\n",
    "prediction_scores_caption_on_val = prediction_scores_caption_on_val.rename(columns={'watch_ratio': 'predicted_watch_ratio'})\n",
    "prediction_scores_ncf_on_val = prediction_scores_ncf_on_val.rename(columns={'watch_ratio': 'predicted_watch_ratio'})\n",
    "prediction_scores_hybrid_on_val = prediction_scores_hybrid_on_val.rename(columns={'watch_ratio': 'predicted_watch_ratio'})\n",
    "prediction_scores_random_on_val = prediction_scores_random_on_val.rename(columns={'watch_ratio': 'predicted_watch_ratio'})\n",
    "\n",
    "prediction_scores_caption_on_test = prediction_scores_caption_on_test.rename(columns={'watch_ratio': 'predicted_watch_ratio'})\n",
    "prediction_scores_ncf_on_test = prediction_scores_ncf_on_test.rename(columns={'watch_ratio': 'predicted_watch_ratio'})\n",
    "prediction_scores_hybrid_on_test = prediction_scores_hybrid_on_test.rename(columns={'watch_ratio': 'predicted_watch_ratio'})\n",
    "prediction_scores_random_on_test = prediction_scores_random_on_test.rename(columns={'watch_ratio': 'predicted_watch_ratio'})\n",
    "\n",
    "prediction_scores_ncf_on_test_without_clustering = prediction_scores_ncf_on_test_without_clustering.rename(columns={'watch_ratio': 'predicted_watch_ratio'})\n",
    "\n",
    "# Sort\n",
    "prediction_scores_caption_on_val = prediction_scores_caption_on_val.sort_values(by=['user_id', 'video_id'])\n",
    "prediction_scores_ncf_on_val = prediction_scores_ncf_on_val.sort_values(by=['user_id', 'video_id'])\n",
    "prediction_scores_hybrid_on_val = prediction_scores_hybrid_on_val.sort_values(by=['user_id', 'video_id'])\n",
    "prediction_scores_random_on_val = prediction_scores_random_on_val.sort_values(by=['user_id', 'video_id'])\n",
    "\n",
    "prediction_scores_caption_on_test = prediction_scores_caption_on_test.sort_values(by=['user_id', 'video_id'])\n",
    "prediction_scores_ncf_on_test = prediction_scores_ncf_on_test.sort_values(by=['user_id', 'video_id'])\n",
    "prediction_scores_hybrid_on_test = prediction_scores_hybrid_on_test.sort_values(by=['user_id', 'video_id'])\n",
    "prediction_scores_random_on_test = prediction_scores_random_on_test.sort_values(by=['user_id', 'video_id'])\n",
    "\n",
    "prediction_scores_ncf_on_test_without_clustering = prediction_scores_ncf_on_test_without_clustering.sort_values(by=['user_id', 'video_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get user watch history\n",
    "\n",
    "We want to be able to filter out videos that the user has already watched. This is so that we recommend new videos instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_watch_history_from_train = eval_fns.get_user_watch_history(joined_train_data)\n",
    "user_watch_history_from_train_val = eval_fns.get_user_watch_history(joined_train_val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting ground truth videos for each user\n",
    "\n",
    "Next, we process the test set to obtain the ground truth watch ratios. The test set is filtered to only contain videos that are present in training and validation data, as well as those that the user has not watched before. Users and videos that are not in the training data are filtered out as well, as we cannot make recommendations for them. The remaining data is then sorted by user in ascending order and watch_ratio in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain users and videos in training data\n",
    "users_in_train_data = set(joined_train_data['user_id'])\n",
    "videos_in_train_data = set(joined_train_data['video_id'])\n",
    "\n",
    "# Obtain users and videos in training and validation data\n",
    "users_in_train_val_data = set(joined_train_val_data['user_id'])\n",
    "videos_in_train_val_data = set(joined_train_val_data['video_id'])\n",
    "\n",
    "# Get ground truth user-item combinations and their watch ratios\n",
    "ground_truth_val = eval_fns.get_ground_truth(joined_val_data[['user_id', 'video_id', 'watch_ratio']], users_in_train_data, videos_in_train_data, user_watch_history_from_train)\n",
    "ground_truth_test = eval_fns.get_ground_truth(joined_test_data[['user_id', 'video_id', 'watch_ratio']], users_in_train_val_data, videos_in_train_val_data, user_watch_history_from_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>watch_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14</td>\n",
       "      <td>4184</td>\n",
       "      <td>3.234123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>6293</td>\n",
       "      <td>2.442865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>14</td>\n",
       "      <td>5954</td>\n",
       "      <td>1.899621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>14</td>\n",
       "      <td>10354</td>\n",
       "      <td>1.884053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14</td>\n",
       "      <td>1352</td>\n",
       "      <td>1.780083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>14</td>\n",
       "      <td>6270</td>\n",
       "      <td>0.062602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>14</td>\n",
       "      <td>7736</td>\n",
       "      <td>0.060968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>14</td>\n",
       "      <td>10140</td>\n",
       "      <td>0.032761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>14</td>\n",
       "      <td>2755</td>\n",
       "      <td>0.032283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>14</td>\n",
       "      <td>10094</td>\n",
       "      <td>0.031986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id video_id  watch_ratio\n",
       "27       14     4184     3.234123\n",
       "0        14     6293     2.442865\n",
       "184      14     5954     1.899621\n",
       "31       14    10354     1.884053\n",
       "18       14     1352     1.780083\n",
       "..      ...      ...          ...\n",
       "169      14     6270     0.062602\n",
       "113      14     7736     0.060968\n",
       "116      14    10140     0.032761\n",
       "183      14     2755     0.032283\n",
       "237      14    10094     0.031986\n",
       "\n",
       "[157 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ground ground truth watch ratios for user 14\n",
    "ground_truth_test[ground_truth_test['user_id'] == 14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting recommendations for each user\n",
    "\n",
    "With the prediction scores generated from our models, we obtain the video recommendations for each user. This is done by first filtering for videos that the user has not watched before, then sorting the predicted watch ratio in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1411/1411 [00:06<00:00, 216.18it/s]\n",
      "100%|██████████| 1411/1411 [00:05<00:00, 275.66it/s]\n",
      "100%|██████████| 1411/1411 [00:04<00:00, 291.48it/s]\n",
      "100%|██████████| 1411/1411 [00:06<00:00, 222.08it/s]\n",
      "100%|██████████| 1411/1411 [00:04<00:00, 283.16it/s]\n",
      "100%|██████████| 1411/1411 [00:05<00:00, 280.08it/s]\n",
      "100%|██████████| 1411/1411 [00:04<00:00, 299.13it/s]\n",
      "100%|██████████| 1411/1411 [00:04<00:00, 290.52it/s]\n",
      "100%|██████████| 1411/1411 [00:03<00:00, 370.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get recommendations on validation set\n",
    "videos_in_val_data = set(joined_val_data['video_id'])\n",
    "\n",
    "recommendations_caption_for_val = eval_fns.get_user_recommendations(prediction_scores_caption_on_val, videos_in_val_data, user_watch_history_from_train)\n",
    "recommendations_ncf_for_val = eval_fns.get_user_recommendations(prediction_scores_ncf_on_val, videos_in_val_data, user_watch_history_from_train)\n",
    "recommendations_hybrid_for_val = eval_fns.get_user_recommendations(prediction_scores_hybrid_on_val, videos_in_val_data, user_watch_history_from_train)\n",
    "recommendations_random_for_val = eval_fns.get_user_recommendations(prediction_scores_random_on_val, videos_in_val_data, user_watch_history_from_train)\n",
    "\n",
    "# Get recommendations on test set\n",
    "videos_in_test_data = set(joined_test_data['video_id'])\n",
    "\n",
    "recommendations_caption_for_test = eval_fns.get_user_recommendations(prediction_scores_caption_on_test, videos_in_test_data, user_watch_history_from_train_val)\n",
    "recommendations_ncf_for_test = eval_fns.get_user_recommendations(prediction_scores_ncf_on_test, videos_in_test_data, user_watch_history_from_train_val)\n",
    "recommendations_hybrid_for_test = eval_fns.get_user_recommendations(prediction_scores_hybrid_on_test, videos_in_test_data, user_watch_history_from_train_val)\n",
    "recommendations_random_for_test = eval_fns.get_user_recommendations(prediction_scores_random_on_test, videos_in_test_data, user_watch_history_from_train_val)\n",
    "\n",
    "recommendations_ncf_for_test_without_clustering = eval_fns.get_user_recommendations(prediction_scores_ncf_on_test_without_clustering, videos_in_test_data, user_watch_history_from_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>predicted_watch_ratio</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143915</th>\n",
       "      <td>14</td>\n",
       "      <td>1306</td>\n",
       "      <td>1.224071e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152254</th>\n",
       "      <td>14</td>\n",
       "      <td>1352</td>\n",
       "      <td>1.217318e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422868</th>\n",
       "      <td>14</td>\n",
       "      <td>4719</td>\n",
       "      <td>1.121088e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156289</th>\n",
       "      <td>14</td>\n",
       "      <td>1379</td>\n",
       "      <td>1.109590e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830672</th>\n",
       "      <td>14</td>\n",
       "      <td>10404</td>\n",
       "      <td>1.068774e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648559</th>\n",
       "      <td>14</td>\n",
       "      <td>7736</td>\n",
       "      <td>1.086311e-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797585</th>\n",
       "      <td>14</td>\n",
       "      <td>9986</td>\n",
       "      <td>8.865571e-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130465</th>\n",
       "      <td>14</td>\n",
       "      <td>1166</td>\n",
       "      <td>2.004953e-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811573</th>\n",
       "      <td>14</td>\n",
       "      <td>10140</td>\n",
       "      <td>1.299631e-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515404</th>\n",
       "      <td>14</td>\n",
       "      <td>5961</td>\n",
       "      <td>6.616041e-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  video_id  predicted_watch_ratio  cluster\n",
       "143915       14      1306           1.224071e+00        0\n",
       "152254       14      1352           1.217318e+00        0\n",
       "422868       14      4719           1.121088e+00        0\n",
       "156289       14      1379           1.109590e+00        0\n",
       "830672       14     10404           1.068774e+00        0\n",
       "...         ...       ...                    ...      ...\n",
       "648559       14      7736           1.086311e-07        0\n",
       "797585       14      9986           8.865571e-08        0\n",
       "130465       14      1166           2.004953e-08        0\n",
       "811573       14     10140           1.299631e-09        0\n",
       "515404       14      5961           6.616041e-12        0\n",
       "\n",
       "[226 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recommendations from NCF model for user 14 to be evaluated on the test set\n",
    "recommendations_ncf_for_test[recommendations_ncf_for_test['user_id'] == 14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "We have chosen various evaluation metrics to provide a comprehensive evaluation of our models' performance. They can be grouped into 3 broad categories - Engagement, Relevance and Diversity.\n",
    "\n",
    "### Engagement\n",
    "1. **Average Watch Ratio @ k**: Measures the average proportion of content that users watch across all recommended videos.\n",
    "\n",
    "### Relevance\n",
    "1. **Precision@k**: Proportion of recommended videos in top K that are relevant.\n",
    "\n",
    "2. **Recall@k**: Proportion of all relevant videos that appear in top K recommendations.\n",
    "\n",
    "3. **F1-Score@k**: The harmonic mean of precision and recall at K, balancing the trade-off between recommending relevant videos (precision) and capturing all relevant videos (recall). \n",
    "\n",
    "As these metrics require a binary label, we establish a threshold for predicted_watch_ratio of 0.7, where if a video has `predicted_watch_ratio` >= 0.7: relevant, `predicted_watch_ratio` < 0.7: irrelevant.\n",
    "\n",
    "### Diversity\n",
    "1. **Category-Aware NDCG @ k**: Measures how well the recommended videos' category distribution matches the user's true category preference ranking.\n",
    "\n",
    "2. **Distinct Categories @ k**: Number of distinct categories that appear in the top K recommendations.\n",
    "\n",
    "\n",
    "We have chosen k to be 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "threshold = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Validation\n",
    "reco_grp_caption_for_val = recommendations_caption_for_val.groupby('user_id')\n",
    "reco_grp_ncf_for_val = recommendations_ncf_for_val.groupby('user_id')\n",
    "reco_grp_hybrid_for_val = recommendations_hybrid_for_val.groupby('user_id')\n",
    "reco_grp_random_for_val = recommendations_random_for_val.groupby('user_id')\n",
    "\n",
    "ground_truth_grp_for_val = ground_truth_val.groupby('user_id')\n",
    "\n",
    "# For Test\n",
    "reco_grp_caption_for_test = recommendations_caption_for_test.groupby('user_id')\n",
    "reco_grp_ncf_for_test = recommendations_ncf_for_test.groupby('user_id')\n",
    "reco_grp_hybrid_for_test = recommendations_hybrid_for_test.groupby('user_id')\n",
    "reco_grp_random_for_test = recommendations_random_for_test.groupby('user_id')\n",
    "\n",
    "reco_grp_ncf_for_test_without_clustering = recommendations_ncf_for_test_without_clustering.groupby('user_id')\n",
    "\n",
    "ground_truth_grp_for_test = ground_truth_test.groupby('user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Across Models on the Validation Set\n",
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1411/1411 [00:59<00:00, 23.89it/s]\n",
      "100%|██████████| 1411/1411 [00:28<00:00, 49.38it/s]\n",
      "100%|██████████| 1411/1411 [00:01<00:00, 1210.24it/s]\n",
      "100%|██████████| 1411/1411 [00:25<00:00, 54.95it/s]\n",
      "100%|██████████| 1411/1411 [00:58<00:00, 24.21it/s]\n",
      "100%|██████████| 1411/1411 [00:32<00:00, 43.45it/s]\n",
      "100%|██████████| 1411/1411 [00:01<00:00, 1021.02it/s]\n",
      "100%|██████████| 1411/1411 [00:31<00:00, 44.62it/s]\n",
      "100%|██████████| 1411/1411 [01:12<00:00, 19.44it/s]\n",
      "100%|██████████| 1411/1411 [00:35<00:00, 40.26it/s]\n",
      "100%|██████████| 1411/1411 [00:01<00:00, 1040.91it/s]\n",
      "100%|██████████| 1411/1411 [00:31<00:00, 44.76it/s]\n",
      "100%|██████████| 1411/1411 [01:10<00:00, 19.95it/s]\n",
      "100%|██████████| 1411/1411 [00:35<00:00, 39.64it/s]\n",
      "100%|██████████| 1411/1411 [00:01<00:00, 1110.69it/s]\n",
      "100%|██████████| 1411/1411 [00:26<00:00, 53.11it/s]\n"
     ]
    }
   ],
   "source": [
    "metrics_df_caption_for_val = eval_fns.get_all_metrics(k, ground_truth_grp_for_val, reco_grp_caption_for_val, video_data, threshold, by_cluster = False)\n",
    "metrics_df_ncf_for_val = eval_fns.get_all_metrics(k, ground_truth_grp_for_val, reco_grp_ncf_for_val, video_data, threshold, by_cluster = False)\n",
    "metrics_df_hybrid_for_val = eval_fns.get_all_metrics(k, ground_truth_grp_for_val, reco_grp_hybrid_for_val, video_data, threshold, by_cluster = False)\n",
    "metrics_df_random_for_val = eval_fns.get_all_metrics(k, ground_truth_grp_for_val, reco_grp_random_for_val, video_data, threshold, by_cluster = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg Watch Ratio @ 100</th>\n",
       "      <th>Avg Precision@100</th>\n",
       "      <th>Avg Recall@100</th>\n",
       "      <th>Avg F1@100</th>\n",
       "      <th>Category-Aware NDCG @ 100</th>\n",
       "      <th>Distinct Categories @ 100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neural Collaborative Filtering with Time Decay</th>\n",
       "      <td>1.036080</td>\n",
       "      <td>0.709447</td>\n",
       "      <td>0.323266</td>\n",
       "      <td>0.435504</td>\n",
       "      <td>0.950681</td>\n",
       "      <td>24.956768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caption-based Video Filtering with Time Decay</th>\n",
       "      <td>0.862624</td>\n",
       "      <td>0.575330</td>\n",
       "      <td>0.260211</td>\n",
       "      <td>0.351417</td>\n",
       "      <td>0.868736</td>\n",
       "      <td>18.795889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hybrid</th>\n",
       "      <td>1.034439</td>\n",
       "      <td>0.707980</td>\n",
       "      <td>0.322404</td>\n",
       "      <td>0.434463</td>\n",
       "      <td>0.952720</td>\n",
       "      <td>24.672573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.557066</td>\n",
       "      <td>0.252694</td>\n",
       "      <td>0.340944</td>\n",
       "      <td>0.921808</td>\n",
       "      <td>25.933381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Avg Watch Ratio @ 100  \\\n",
       "Neural Collaborative Filtering with Time Decay               1.036080   \n",
       "Caption-based Video Filtering with Time Decay                0.862624   \n",
       "Hybrid                                                       1.034439   \n",
       "Random                                                       0.843575   \n",
       "\n",
       "                                                Avg Precision@100  \\\n",
       "Neural Collaborative Filtering with Time Decay           0.709447   \n",
       "Caption-based Video Filtering with Time Decay            0.575330   \n",
       "Hybrid                                                   0.707980   \n",
       "Random                                                   0.557066   \n",
       "\n",
       "                                                Avg Recall@100  Avg F1@100  \\\n",
       "Neural Collaborative Filtering with Time Decay        0.323266    0.435504   \n",
       "Caption-based Video Filtering with Time Decay         0.260211    0.351417   \n",
       "Hybrid                                                0.322404    0.434463   \n",
       "Random                                                0.252694    0.340944   \n",
       "\n",
       "                                                Category-Aware NDCG @ 100  \\\n",
       "Neural Collaborative Filtering with Time Decay                   0.950681   \n",
       "Caption-based Video Filtering with Time Decay                    0.868736   \n",
       "Hybrid                                                           0.952720   \n",
       "Random                                                           0.921808   \n",
       "\n",
       "                                                Distinct Categories @ 100  \n",
       "Neural Collaborative Filtering with Time Decay                  24.956768  \n",
       "Caption-based Video Filtering with Time Decay                   18.795889  \n",
       "Hybrid                                                          24.672573  \n",
       "Random                                                          25.933381  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the metrics dataframes\n",
    "metrics_for_val_combined = pd.concat([metrics_df_ncf_for_val, metrics_df_caption_for_val, metrics_df_hybrid_for_val, metrics_df_random_for_val], axis=0)\n",
    "\n",
    "# Add model names\n",
    "metrics_for_val_combined.index = ['Neural Collaborative Filtering with Time Decay', 'Caption-based Video Filtering with Time Decay', 'Hybrid', 'Random']\n",
    "\n",
    "metrics_for_val_combined.drop(columns=['cluster'], inplace=True)\n",
    "\n",
    "metrics_for_val_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Across Models on the Testing Set\n",
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1411/1411 [01:01<00:00, 22.88it/s]\n",
      "100%|██████████| 1411/1411 [00:30<00:00, 45.76it/s]\n",
      "100%|██████████| 1411/1411 [00:01<00:00, 1264.72it/s]\n",
      "100%|██████████| 1411/1411 [00:28<00:00, 49.03it/s]\n",
      "100%|██████████| 1411/1411 [00:59<00:00, 23.71it/s]\n",
      "100%|██████████| 1411/1411 [00:29<00:00, 48.34it/s]\n",
      "100%|██████████| 1411/1411 [00:01<00:00, 1381.64it/s]\n",
      "100%|██████████| 1411/1411 [00:24<00:00, 57.05it/s]\n",
      "100%|██████████| 1411/1411 [00:59<00:00, 23.85it/s]\n",
      "100%|██████████| 1411/1411 [00:29<00:00, 48.40it/s]\n",
      "100%|██████████| 1411/1411 [00:01<00:00, 1259.59it/s]\n",
      "100%|██████████| 1411/1411 [00:24<00:00, 57.61it/s]\n",
      "100%|██████████| 1411/1411 [00:59<00:00, 23.56it/s]\n",
      "100%|██████████| 1411/1411 [00:32<00:00, 42.80it/s]\n",
      "100%|██████████| 1411/1411 [00:01<00:00, 1227.90it/s]\n",
      "100%|██████████| 1411/1411 [00:25<00:00, 55.43it/s]\n",
      "100%|██████████| 1411/1411 [00:58<00:00, 23.95it/s]\n",
      "100%|██████████| 1411/1411 [00:34<00:00, 40.59it/s]\n",
      "100%|██████████| 1411/1411 [00:01<00:00, 1149.37it/s]\n",
      "100%|██████████| 1411/1411 [00:18<00:00, 76.69it/s] \n"
     ]
    }
   ],
   "source": [
    "metrics_df_caption_for_test = eval_fns.get_all_metrics(k, ground_truth_grp_for_test, reco_grp_caption_for_test, video_data, threshold, by_cluster = False)\n",
    "metrics_df_ncf_for_test = eval_fns.get_all_metrics(k, ground_truth_grp_for_test, reco_grp_ncf_for_test, video_data, threshold, by_cluster = False)\n",
    "metrics_df_hybrid_for_test = eval_fns.get_all_metrics(k, ground_truth_grp_for_test, reco_grp_hybrid_for_test, video_data, threshold, by_cluster = False)\n",
    "metrics_df_random_for_test = eval_fns.get_all_metrics(k, ground_truth_grp_for_test, reco_grp_random_for_test, video_data, threshold, by_cluster = False)\n",
    "\n",
    "metrics_df_ncf_for_test_without_clustering = eval_fns.get_all_metrics(k, ground_truth_grp_for_test, reco_grp_ncf_for_test_without_clustering, video_data, threshold, by_cluster = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg Watch Ratio @ 100</th>\n",
       "      <th>Avg Precision@100</th>\n",
       "      <th>Avg Recall@100</th>\n",
       "      <th>Avg F1@100</th>\n",
       "      <th>Category-Aware NDCG @ 100</th>\n",
       "      <th>Distinct Categories @ 100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neural Collaborative Filtering with Time Decay</th>\n",
       "      <td>0.937810</td>\n",
       "      <td>0.629683</td>\n",
       "      <td>0.775293</td>\n",
       "      <td>0.676081</td>\n",
       "      <td>0.970287</td>\n",
       "      <td>25.734940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caption-based Video Filtering with Time Decay</th>\n",
       "      <td>0.821867</td>\n",
       "      <td>0.534254</td>\n",
       "      <td>0.662118</td>\n",
       "      <td>0.575053</td>\n",
       "      <td>0.907141</td>\n",
       "      <td>21.408930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hybrid</th>\n",
       "      <td>0.911009</td>\n",
       "      <td>0.605267</td>\n",
       "      <td>0.742098</td>\n",
       "      <td>0.648776</td>\n",
       "      <td>0.962718</td>\n",
       "      <td>25.575478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.797052</td>\n",
       "      <td>0.510781</td>\n",
       "      <td>0.635939</td>\n",
       "      <td>0.550876</td>\n",
       "      <td>0.929594</td>\n",
       "      <td>26.715804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Avg Watch Ratio @ 100  \\\n",
       "Neural Collaborative Filtering with Time Decay               0.937810   \n",
       "Caption-based Video Filtering with Time Decay                0.821867   \n",
       "Hybrid                                                       0.911009   \n",
       "Random                                                       0.797052   \n",
       "\n",
       "                                                Avg Precision@100  \\\n",
       "Neural Collaborative Filtering with Time Decay           0.629683   \n",
       "Caption-based Video Filtering with Time Decay            0.534254   \n",
       "Hybrid                                                   0.605267   \n",
       "Random                                                   0.510781   \n",
       "\n",
       "                                                Avg Recall@100  Avg F1@100  \\\n",
       "Neural Collaborative Filtering with Time Decay        0.775293    0.676081   \n",
       "Caption-based Video Filtering with Time Decay         0.662118    0.575053   \n",
       "Hybrid                                                0.742098    0.648776   \n",
       "Random                                                0.635939    0.550876   \n",
       "\n",
       "                                                Category-Aware NDCG @ 100  \\\n",
       "Neural Collaborative Filtering with Time Decay                   0.970287   \n",
       "Caption-based Video Filtering with Time Decay                    0.907141   \n",
       "Hybrid                                                           0.962718   \n",
       "Random                                                           0.929594   \n",
       "\n",
       "                                                Distinct Categories @ 100  \n",
       "Neural Collaborative Filtering with Time Decay                  25.734940  \n",
       "Caption-based Video Filtering with Time Decay                   21.408930  \n",
       "Hybrid                                                          25.575478  \n",
       "Random                                                          26.715804  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the metrics dataframes\n",
    "metrics_for_test_combined = pd.concat([metrics_df_ncf_for_test, metrics_df_caption_for_test, metrics_df_hybrid_for_test, metrics_df_random_for_test], axis=0)\n",
    "\n",
    "# Add model names\n",
    "metrics_for_test_combined.index = ['Neural Collaborative Filtering with Time Decay', 'Caption-based Video Filtering with Time Decay', 'Hybrid', 'Random']\n",
    "\n",
    "metrics_for_test_combined.drop(columns=['cluster'], inplace=True)\n",
    "\n",
    "metrics_for_test_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "1. Engagement\n",
    "\n",
    "    As we can see, the Average Watch Ratio @ k is higher for all of our models compared to the random baseline, indicating that the users are watching more of the recommended videos. This is a good sign as it shows that our models are able to recommend videos that users are more likely to watch and enjoy. The NCF model performs much better than the Caption-based model, which is expected as the NCF model is a much more complex model that is able to capture more complex patterns in the data.\n",
    "\n",
    "2. Relevance\n",
    "\n",
    "    The Precision@k, Recall@k and F1-Score@k are all higher for all of our models compared to the random baseline. This indicates that our models are able to recommend more relevant videos to the users. The higher F1-score@k also indicates that our models are able to balance the trade-off between recommending relevant videos and capturing all relevant videos. Similar to the engagement metrics, the NCF model performs much better than the Caption-based model.\n",
    "\n",
    "3. Diversity\n",
    "\n",
    "    In terms of Distinct Categories @ k, we can see that all our models recommend fewer number of distinct categories compared to the random baseline. Caption-based model recommends the least number of distinct categories, which is expected as the model's recommendations were partially based on the embeddings of the category of the video. In general, this suggests that our models are more targeted than random recommendations, but might not be as diverse in terms of the categories of the recommended videos. However, as we can see from the Category-Aware NDCG @ 100 metric, the NCF model has higher scores compared to our baseline, which means that even though the number of distinct categories recommended is lower, the categories of the recommended videos are more aligned with the user's true category preference ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCF Model Performance\n",
    "\n",
    "Previously, we segmented users into four distinct clusters based on their behavioral patterns, in hopes to capture subtle patterns unique to each group and improve model performance. Hence, we have trained the NCF model on both segmented and non-segmented combined train and validation data. \n",
    "\n",
    "Let us see if performance is indeed better with customer segmentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "##### Performance With User Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [00:15<00:00, 17.24it/s]\n",
      "100%|██████████| 419/419 [00:25<00:00, 16.35it/s]\n",
      "100%|██████████| 345/345 [00:20<00:00, 16.48it/s]\n",
      "100%|██████████| 378/378 [00:22<00:00, 16.78it/s]\n",
      "100%|██████████| 269/269 [00:05<00:00, 44.84it/s]\n",
      "100%|██████████| 419/419 [00:08<00:00, 47.24it/s]\n",
      "100%|██████████| 345/345 [00:07<00:00, 46.86it/s]\n",
      "100%|██████████| 378/378 [00:08<00:00, 46.92it/s]\n",
      "100%|██████████| 269/269 [00:03<00:00, 79.06it/s]\n",
      "100%|██████████| 419/419 [00:05<00:00, 79.38it/s]\n",
      "100%|██████████| 345/345 [00:04<00:00, 79.28it/s]\n",
      "100%|██████████| 378/378 [00:04<00:00, 80.95it/s]\n",
      "100%|██████████| 269/269 [00:07<00:00, 34.50it/s]\n",
      "100%|██████████| 419/419 [00:12<00:00, 34.46it/s]\n",
      "100%|██████████| 345/345 [00:10<00:00, 33.80it/s]\n",
      "100%|██████████| 378/378 [00:10<00:00, 34.89it/s]\n"
     ]
    }
   ],
   "source": [
    "metrics_ncf_per_cluster = eval_fns.get_all_metrics(k, ground_truth_test, recommendations_ncf_for_test, video_data, threshold, by_cluster=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>Avg Watch Ratio @ 100</th>\n",
       "      <th>Avg Precision@100</th>\n",
       "      <th>Avg Recall@100</th>\n",
       "      <th>Avg F1@100</th>\n",
       "      <th>Category-Aware NDCG @ 100</th>\n",
       "      <th>Distinct Categories @ 100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.955919</td>\n",
       "      <td>0.609204</td>\n",
       "      <td>0.760632</td>\n",
       "      <td>0.657452</td>\n",
       "      <td>0.967586</td>\n",
       "      <td>26.230483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.941045</td>\n",
       "      <td>0.654094</td>\n",
       "      <td>0.768648</td>\n",
       "      <td>0.686297</td>\n",
       "      <td>0.970797</td>\n",
       "      <td>25.842482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.916312</td>\n",
       "      <td>0.609012</td>\n",
       "      <td>0.780041</td>\n",
       "      <td>0.665949</td>\n",
       "      <td>0.970502</td>\n",
       "      <td>25.637681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.940958</td>\n",
       "      <td>0.636063</td>\n",
       "      <td>0.788758</td>\n",
       "      <td>0.687261</td>\n",
       "      <td>0.971448</td>\n",
       "      <td>25.351852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overall</td>\n",
       "      <td>0.937810</td>\n",
       "      <td>0.629683</td>\n",
       "      <td>0.775293</td>\n",
       "      <td>0.676081</td>\n",
       "      <td>0.970287</td>\n",
       "      <td>25.734940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster  Avg Watch Ratio @ 100  Avg Precision@100  Avg Recall@100  \\\n",
       "0        0               0.955919           0.609204        0.760632   \n",
       "0        1               0.941045           0.654094        0.768648   \n",
       "0        2               0.916312           0.609012        0.780041   \n",
       "0        3               0.940958           0.636063        0.788758   \n",
       "0  Overall               0.937810           0.629683        0.775293   \n",
       "\n",
       "   Avg F1@100  Category-Aware NDCG @ 100  Distinct Categories @ 100  \n",
       "0    0.657452                   0.967586                  26.230483  \n",
       "0    0.686297                   0.970797                  25.842482  \n",
       "0    0.665949                   0.970502                  25.637681  \n",
       "0    0.687261                   0.971448                  25.351852  \n",
       "0    0.676081                   0.970287                  25.734940  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_ncf_per_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Performance Without Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1411/1411 [01:11<00:00, 19.79it/s]\n",
      "100%|██████████| 1411/1411 [00:27<00:00, 52.11it/s]\n",
      "100%|██████████| 1411/1411 [00:16<00:00, 83.71it/s]\n",
      "100%|██████████| 1411/1411 [00:30<00:00, 46.61it/s]\n"
     ]
    }
   ],
   "source": [
    "metrics_ncf_per_without_clustering = eval_fns.get_all_metrics(k, ground_truth_test, recommendations_ncf_for_test_without_clustering, video_data, threshold, by_cluster=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>Avg Watch Ratio @ 100</th>\n",
       "      <th>Avg Precision@100</th>\n",
       "      <th>Avg Recall@100</th>\n",
       "      <th>Avg F1@100</th>\n",
       "      <th>Category-Aware NDCG @ 100</th>\n",
       "      <th>Distinct Categories @ 100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overall</td>\n",
       "      <td>0.819306</td>\n",
       "      <td>0.514577</td>\n",
       "      <td>0.341954</td>\n",
       "      <td>0.399085</td>\n",
       "      <td>0.895342</td>\n",
       "      <td>25.192771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster  Avg Watch Ratio @ 100  Avg Precision@100  Avg Recall@100  \\\n",
       "0  Overall               0.819306           0.514577        0.341954   \n",
       "\n",
       "   Avg F1@100  Category-Aware NDCG @ 100  Distinct Categories @ 100  \n",
       "0    0.399085                   0.895342                  25.192771  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_ncf_per_without_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
